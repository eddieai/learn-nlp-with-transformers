
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <title>4.6-ç”Ÿæˆä»»åŠ¡-æœºå™¨ç¿»è¯‘ Â· HonKit</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="HonKit 5.1.4">
        
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/@honkit/honkit-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=3, user-scalable=yes">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="4.7-ç”Ÿæˆä»»åŠ¡-æ‘˜è¦ç”Ÿæˆ.html" />
    
    
    <link rel="prev" href="4.5-ç”Ÿæˆä»»åŠ¡-è¯­è¨€æ¨¡å‹.html" />
    

    </head>
    <body>
        
<div class="book honkit-cloak">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        <li class="header">ç¯‡ç« 1-å‰è¨€</li>
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="../ç¯‡ç« 1-å‰è¨€/1.0-æœ¬åœ°é˜…è¯»å’Œä»£ç è¿è¡Œç¯å¢ƒé…ç½®.html">
            
                <a href="../ç¯‡ç« 1-å‰è¨€/1.0-æœ¬åœ°é˜…è¯»å’Œä»£ç è¿è¡Œç¯å¢ƒé…ç½®.html">
            
                    
                    1.0-æœ¬åœ°é˜…è¯»å’Œä»£ç è¿è¡Œç¯å¢ƒé…ç½®
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="../ç¯‡ç« 1-å‰è¨€/1.1-Transformersåœ¨NLPä¸­çš„å…´èµ·.html">
            
                <a href="../ç¯‡ç« 1-å‰è¨€/1.1-Transformersåœ¨NLPä¸­çš„å…´èµ·.html">
            
                    
                    1.1-Transformersåœ¨NLPä¸­çš„å…´èµ·
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">ç¯‡ç« 2-Transformerç›¸å…³åŸç†</li>
        
        
    
        <li class="chapter " data-level="2.1" data-path="../ç¯‡ç« 2-Transformerç›¸å…³åŸç†/2.0-å‰è¨€.html">
            
                <a href="../ç¯‡ç« 2-Transformerç›¸å…³åŸç†/2.0-å‰è¨€.html">
            
                    
                    2.0-å‰è¨€
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.2" data-path="../ç¯‡ç« 2-Transformerç›¸å…³åŸç†/2.1-å›¾è§£attention.html">
            
                <a href="../ç¯‡ç« 2-Transformerç›¸å…³åŸç†/2.1-å›¾è§£attention.html">
            
                    
                    2.1-å›¾è§£attention
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.3" data-path="../ç¯‡ç« 2-Transformerç›¸å…³åŸç†/2.2-å›¾è§£transformer.html">
            
                <a href="../ç¯‡ç« 2-Transformerç›¸å…³åŸç†/2.2-å›¾è§£transformer.html">
            
                    
                    2.2-å›¾è§£transformer
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.4" data-path="../ç¯‡ç« 2-Transformerç›¸å…³åŸç†/2.2.1-Pytorchç¼–å†™Transformer.html">
            
                <a href="../ç¯‡ç« 2-Transformerç›¸å…³åŸç†/2.2.1-Pytorchç¼–å†™Transformer.html">
            
                    
                    2.2.1-Pytorchç¼–å†™Transformer
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.5" data-path="../ç¯‡ç« 2-Transformerç›¸å…³åŸç†/2.2.1-Pytorchç¼–å†™Transformer-é€‰è¯».md">
            
                <span>
            
                    
                    2.2.2-Pytorchç¼–å†™Transformer-é€‰è¯»
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.6" data-path="../ç¯‡ç« 2-Transformerç›¸å…³åŸç†/2.3-å›¾è§£BERT.html">
            
                <a href="../ç¯‡ç« 2-Transformerç›¸å…³åŸç†/2.3-å›¾è§£BERT.html">
            
                    
                    2.3-å›¾è§£BERT
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.7" data-path="../ç¯‡ç« 2-Transformerç›¸å…³åŸç†/2.4-å›¾è§£GPT.html">
            
                <a href="../ç¯‡ç« 2-Transformerç›¸å…³åŸç†/2.4-å›¾è§£GPT.html">
            
                    
                    2.4-å›¾è§£GPT
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.8" data-path="../ç¯‡ç« 2-Transformerç›¸å…³åŸç†/2.5-ç¯‡ç« å°æµ‹.html">
            
                <a href="../ç¯‡ç« 2-Transformerç›¸å…³åŸç†/2.5-ç¯‡ç« å°æµ‹.html">
            
                    
                    2.5-ç¯‡ç« å°æµ‹
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">ç¯‡ç« 3-ç¼–å†™ä¸€ä¸ªTransformeræ¨¡å‹ï¼šBERT</li>
        
        
    
        <li class="chapter " data-level="3.1" data-path="../ç¯‡ç« 3-ç¼–å†™ä¸€ä¸ªTransformeræ¨¡å‹ï¼šBERT/3.1-å¦‚ä½•å®ç°ä¸€ä¸ªBERT.html">
            
                <a href="../ç¯‡ç« 3-ç¼–å†™ä¸€ä¸ªTransformeræ¨¡å‹ï¼šBERT/3.1-å¦‚ä½•å®ç°ä¸€ä¸ªBERT.html">
            
                    
                    3.1-å¦‚ä½•å®ç°ä¸€ä¸ªBERT
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.2" data-path="../ç¯‡ç« 3-ç¼–å†™ä¸€ä¸ªTransformeræ¨¡å‹ï¼šBERT/3.2-å¦‚ä½•åº”ç”¨ä¸€ä¸ªBERT.html">
            
                <a href="../ç¯‡ç« 3-ç¼–å†™ä¸€ä¸ªTransformeræ¨¡å‹ï¼šBERT/3.2-å¦‚ä½•åº”ç”¨ä¸€ä¸ªBERT.html">
            
                    
                    3.2-å¦‚ä½•åº”ç”¨ä¸€ä¸ªBERT
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.3" data-path="../ç¯‡ç« 3-ç¼–å†™ä¸€ä¸ªTransformeræ¨¡å‹ï¼šBERT/3.3-ç¯‡ç« å°æµ‹.html">
            
                <a href="../ç¯‡ç« 3-ç¼–å†™ä¸€ä¸ªTransformeræ¨¡å‹ï¼šBERT/3.3-ç¯‡ç« å°æµ‹.html">
            
                    
                    3.3-ç¯‡ç« å°æµ‹
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">ç¯‡ç« 4-ä½¿ç”¨Transformersè§£å†³NLPä»»åŠ¡</li>
        
        
    
        <li class="chapter " data-level="4.1" data-path="4.0-å‰è¨€.html">
            
                <a href="4.0-å‰è¨€.html">
            
                    
                    4.0-å‰è¨€
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.2" data-path="4.0-åŸºäºHuggingFace-Transformersçš„é¢„è®­ç»ƒæ¨¡å‹å¾®è°ƒ.html">
            
                <a href="4.0-åŸºäºHuggingFace-Transformersçš„é¢„è®­ç»ƒæ¨¡å‹å¾®è°ƒ.html">
            
                    
                    4.0-åŸºäºHuggingFace-Transformersçš„é¢„è®­ç»ƒæ¨¡å‹å¾®è°ƒ
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.3" data-path="4.1-æ–‡æœ¬åˆ†ç±».html">
            
                <a href="4.1-æ–‡æœ¬åˆ†ç±».html">
            
                    
                    4.1-æ–‡æœ¬åˆ†ç±»
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.4" data-path="4.2-åºåˆ—æ ‡æ³¨.html">
            
                <a href="4.2-åºåˆ—æ ‡æ³¨.html">
            
                    
                    4.2-åºåˆ—æ ‡æ³¨
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.5" data-path="4.3-é—®ç­”ä»»åŠ¡-æŠ½å–å¼é—®ç­”.html">
            
                <a href="4.3-é—®ç­”ä»»åŠ¡-æŠ½å–å¼é—®ç­”.html">
            
                    
                    4.3-é—®ç­”ä»»åŠ¡-æŠ½å–å¼é—®ç­”
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.6" data-path="4.4-é—®ç­”ä»»åŠ¡-å¤šé€‰é—®ç­”.html">
            
                <a href="4.4-é—®ç­”ä»»åŠ¡-å¤šé€‰é—®ç­”.html">
            
                    
                    4.4-é—®ç­”ä»»åŠ¡-å¤šé€‰é—®ç­”
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.7" data-path="4.5-ç”Ÿæˆä»»åŠ¡-è¯­è¨€æ¨¡å‹.html">
            
                <a href="4.5-ç”Ÿæˆä»»åŠ¡-è¯­è¨€æ¨¡å‹.html">
            
                    
                    4.5-ç”Ÿæˆä»»åŠ¡-è¯­è¨€æ¨¡å‹
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="4.8" data-path="4.6-ç”Ÿæˆä»»åŠ¡-æœºå™¨ç¿»è¯‘.html">
            
                <a href="4.6-ç”Ÿæˆä»»åŠ¡-æœºå™¨ç¿»è¯‘.html">
            
                    
                    4.6-ç”Ÿæˆä»»åŠ¡-æœºå™¨ç¿»è¯‘
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.9" data-path="4.7-ç”Ÿæˆä»»åŠ¡-æ‘˜è¦ç”Ÿæˆ.html">
            
                <a href="4.7-ç”Ÿæˆä»»åŠ¡-æ‘˜è¦ç”Ÿæˆ.html">
            
                    
                    4.7-ç”Ÿæˆä»»åŠ¡-æ‘˜è¦ç”Ÿæˆ
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.10" data-path="4.8-ç¯‡ç« å°æµ‹.html">
            
                <a href="4.8-ç¯‡ç« å°æµ‹.html">
            
                    
                    4.8-ç¯‡ç« å°æµ‹
            
                </a>
            

            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://github.com/honkit/honkit" target="blank" class="gitbook-link">
            Published with HonKit
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >4.6-ç”Ÿæˆä»»åŠ¡-æœºå™¨ç¿»è¯‘</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <p>æœ¬æ–‡æ¶‰åŠçš„jupter notebookåœ¨<a href="https://github.com/datawhalechina/learn-nlp-with-transformers/tree/main/docs/%E7%AF%87%E7%AB%A04-%E4%BD%BF%E7%94%A8Transformers%E8%A7%A3%E5%86%B3NLP%E4%BB%BB%E5%8A%A1" target="_blank">ç¯‡ç« 4ä»£ç åº“ä¸­</a>ã€‚</p>
<p>å»ºè®®ç›´æ¥ä½¿ç”¨google colab notebookæ‰“å¼€æœ¬æ•™ç¨‹ï¼Œå¯ä»¥å¿«é€Ÿä¸‹è½½ç›¸å…³æ•°æ®é›†å’Œæ¨¡å‹ã€‚
å¦‚æœæ‚¨æ­£åœ¨googleçš„colabä¸­æ‰“å¼€è¿™ä¸ªnotebookï¼Œæ‚¨å¯èƒ½éœ€è¦å®‰è£…Transformerså’ŒğŸ¤—Datasetsåº“ã€‚å°†ä»¥ä¸‹å‘½ä»¤å–æ¶ˆæ³¨é‡Šå³å¯å®‰è£…ã€‚</p>
<pre><code class="lang-python">! pip install datasets transformers <span class="hljs-string">"sacrebleu&gt;=1.4.12,&lt;2.0.0"</span> sentencepiece
</code></pre>
<p>å¦‚æœæ‚¨æ­£åœ¨æœ¬åœ°æ‰“å¼€è¿™ä¸ªnotebookï¼Œè¯·ç¡®ä¿æ‚¨è®¤çœŸé˜…è¯»å¹¶å®‰è£…äº†transformer-quick-start-zhçš„readmeæ–‡ä»¶ä¸­çš„æ‰€æœ‰ä¾èµ–åº“ã€‚æ‚¨ä¹Ÿå¯ä»¥åœ¨<a href="https://github.com/huggingface/transformers/tree/master/examples/seq2seq" target="_blank">è¿™é‡Œ</a>æ‰¾åˆ°æœ¬notebookçš„å¤šGPUåˆ†å¸ƒå¼è®­ç»ƒç‰ˆæœ¬ã€‚</p>
<h1 id="å¾®è°ƒtransformeræ¨¡å‹è§£å†³ç¿»è¯‘ä»»åŠ¡">å¾®è°ƒtransformeræ¨¡å‹è§£å†³ç¿»è¯‘ä»»åŠ¡</h1>
<p>åœ¨è¿™ä¸ªnotebookä¸­ï¼Œæˆ‘ä»¬å°†å±•ç¤ºå¦‚ä½•ä½¿ç”¨<a href="https://github.com/huggingface/transformers" target="_blank">ğŸ¤— Transformers</a>ä»£ç åº“ä¸­çš„æ¨¡å‹æ¥è§£å†³è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„ç¿»è¯‘ä»»åŠ¡ã€‚æˆ‘ä»¬å°†ä¼šä½¿ç”¨<a href="http://www.statmt.org/wmt16/" target="_blank">WMT dataset</a>æ•°æ®é›†ã€‚è¿™æ˜¯ç¿»è¯‘ä»»åŠ¡æœ€å¸¸ç”¨çš„æ•°æ®é›†ä¹‹ä¸€ã€‚</p>
<p>ä¸‹é¢å±•ç¤ºäº†ä¸€ä¸ªä¾‹å­ï¼š</p>
<p><img src="https://github.com/huggingface/notebooks/blob/master/examples/images/translation.png?raw=1" alt="Widget inference on a translation task"></img></p>
<p>å¯¹äºç¿»è¯‘ä»»åŠ¡ï¼Œæˆ‘ä»¬å°†å±•ç¤ºå¦‚ä½•ä½¿ç”¨ç®€å•çš„åŠ è½½æ•°æ®é›†ï¼ŒåŒæ—¶é’ˆå¯¹ç›¸åº”çš„ä»æ— ä½¿ç”¨transformerä¸­çš„Traineræ¥å£å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒã€‚</p>
<pre><code class="lang-python">model_checkpoint = <span class="hljs-string">"Helsinki-NLP/opus-mt-en-ro"</span> 
<span class="hljs-comment"># é€‰æ‹©ä¸€ä¸ªæ¨¡å‹checkpoint</span>
</code></pre>
<p>åªè¦é¢„è®­ç»ƒçš„transformeræ¨¡å‹åŒ…å«seq2seqç»“æ„çš„headå±‚ï¼Œé‚£ä¹ˆæœ¬notebookç†è®ºä¸Šå¯ä»¥ä½¿ç”¨å„ç§å„æ ·çš„transformeræ¨¡å‹<a href="https://huggingface.co/models" target="_blank">æ¨¡å‹é¢æ¿</a>ï¼Œè§£å†³ä»»ä½•ç¿»è¯‘ä»»åŠ¡ã€‚</p>
<p>æœ¬æ–‡æˆ‘ä»¬ä½¿ç”¨å·²ç»è®­ç»ƒå¥½çš„<a href="https://huggingface.co/Helsinki-NLP/opus-mt-en-ro" target="_blank"><code>Helsinki-NLP/opus-mt-en-ro</code></a> checkpointæ¥åšç¿»è¯‘ä»»åŠ¡ã€‚ </p>
<h2 id="åŠ è½½æ•°æ®">åŠ è½½æ•°æ®</h2>
<p>æˆ‘ä»¬å°†ä¼šä½¿ç”¨ğŸ¤— Datasetsåº“æ¥åŠ è½½æ•°æ®å’Œå¯¹åº”çš„è¯„æµ‹æ–¹å¼ã€‚æ•°æ®åŠ è½½å’Œè¯„æµ‹æ–¹å¼åŠ è½½åªéœ€è¦ç®€å•ä½¿ç”¨load_datasetå’Œload_metricå³å¯ã€‚æˆ‘ä»¬ä½¿ç”¨WMTæ•°æ®é›†ä¸­çš„English/RomanianåŒè¯­ç¿»è¯‘ã€‚</p>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset, load_metric

raw_datasets = load_dataset(<span class="hljs-string">"wmt16"</span>, <span class="hljs-string">"ro-en"</span>)
metric = load_metric(<span class="hljs-string">"sacrebleu"</span>)
</code></pre>
<pre><code>Downloading: 2.81kB [00:00, 523kB/s]                    
Downloading: 3.19kB [00:00, 758kB/s]                    
Downloading: 41.0kB [00:00, 11.0MB/s]                   


Downloading and preparing dataset wmt16/ro-en (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /Users/niepig/.cache/huggingface/datasets/wmt16/ro-en/1.0.0/0d9fb3e814712c785176ad8cdb9f465fbe6479000ee6546725db30ad8a8b5f8a...


Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 225M/225M [00:18&lt;00:00, 12.2MB/s]
Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 23.5M/23.5M [00:16&lt;00:00, 1.44MB/s]
Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38.7M/38.7M [00:03&lt;00:00, 9.82MB/s]


Dataset wmt16 downloaded and prepared to /Users/niepig/.cache/huggingface/datasets/wmt16/ro-en/1.0.0/0d9fb3e814712c785176ad8cdb9f465fbe6479000ee6546725db30ad8a8b5f8a. Subsequent calls will reuse this data.


Downloading: 5.40kB [00:00, 2.08MB/s]                   
</code></pre><p>è¿™ä¸ªdatasetså¯¹è±¡æœ¬èº«æ˜¯ä¸€ç§<a href="https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasetdict" target="_blank"><code>DatasetDict</code></a>æ•°æ®ç»“æ„. å¯¹äºè®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†ï¼Œåªéœ€è¦ä½¿ç”¨å¯¹åº”çš„keyï¼ˆtrainï¼Œvalidationï¼Œtestï¼‰å³å¯å¾—åˆ°ç›¸åº”çš„æ•°æ®ã€‚</p>
<pre><code class="lang-python">raw_datasets
</code></pre>
<pre><code>DatasetDict({
    train: Dataset({
        features: ['translation'],
        num_rows: 610320
    })
    validation: Dataset({
        features: ['translation'],
        num_rows: 1999
    })
    test: Dataset({
        features: ['translation'],
        num_rows: 1999
    })
})
</code></pre><p>ç»™å®šä¸€ä¸ªæ•°æ®åˆ‡åˆ†çš„keyï¼ˆtrainã€validationæˆ–è€…testï¼‰å’Œä¸‹æ ‡å³å¯æŸ¥çœ‹æ•°æ®ã€‚</p>
<pre><code class="lang-python">raw_datasets[<span class="hljs-string">"train"</span>][<span class="hljs-number">0</span>]
<span class="hljs-comment"># æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ä¸€å¥è‹±è¯­enå¯¹åº”ä¸€å¥ç½—é©¬å°¼äºšè¯­è¨€ro</span>
</code></pre>
<pre><code>{'translation': {'en': 'Membership of Parliament: see Minutes',
  'ro': 'ComponenÅ£a Parlamentului: a se vedea procesul-verbal'}}
</code></pre><p>ä¸ºäº†èƒ½å¤Ÿè¿›ä¸€æ­¥ç†è§£æ•°æ®é•¿ä»€ä¹ˆæ ·å­ï¼Œä¸‹é¢çš„å‡½æ•°å°†ä»æ•°æ®é›†é‡Œéšæœºé€‰æ‹©å‡ ä¸ªä¾‹å­è¿›è¡Œå±•ç¤ºã€‚</p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> datasets
<span class="hljs-keyword">import</span> random
<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">from</span> IPython.display <span class="hljs-keyword">import</span> display, HTML

<span class="hljs-keyword">def</span> <span class="hljs-title function_">show_random_elements</span>(<span class="hljs-params">dataset, num_examples=<span class="hljs-number">5</span></span>):
    <span class="hljs-keyword">assert</span> num_examples &lt;= <span class="hljs-built_in">len</span>(dataset), <span class="hljs-string">"Can't pick more elements than there are in the dataset."</span>
    picks = []
    <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_examples):
        pick = random.randint(<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(dataset)-<span class="hljs-number">1</span>)
        <span class="hljs-keyword">while</span> pick <span class="hljs-keyword">in</span> picks:
            pick = random.randint(<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(dataset)-<span class="hljs-number">1</span>)
        picks.append(pick)

    df = pd.DataFrame(dataset[picks])
    <span class="hljs-keyword">for</span> column, typ <span class="hljs-keyword">in</span> dataset.features.items():
        <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(typ, datasets.ClassLabel):
            df[column] = df[column].transform(<span class="hljs-keyword">lambda</span> i: typ.names[i])
    display(HTML(df.to_html()))
</code></pre>
<pre><code class="lang-python">show_random_elements(raw_datasets[<span class="hljs-string">"train"</span>])
</code></pre>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>translation</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>{'en': 'I do not believe that this is the right course.', 'ro': 'Nu cred cÄƒ acesta este varianta corectÄƒ.'}</td>
    </tr>
    <tr>
      <th>1</th>
      <td>{'en': 'A total of 104 new jobs were created at the European Chemicals Agency, which mainly supervises our REACH projects.', 'ro': 'Un total de 104 noi locuri de muncÄƒ au fost create la AgenÈ›ia EuropeanÄƒ pentru Produse Chimice, care, Ã®n special, supravegheazÄƒ proiectele noastre REACH.'}</td>
    </tr>
    <tr>
      <th>2</th>
      <td>{'en': 'In view of the above, will the Council say what stage discussions for Turkish participation in joint Frontex operations have reached?', 'ro': 'Care este stadiul negocierilor referitoare la participarea Turciei la operaÈ›iunile comune din cadrul Frontex?'}</td>
    </tr>
    <tr>
      <th>3</th>
      <td>{'en': 'We now fear that if the scope of this directive is expanded, the directive will suffer exactly the same fate as the last attempt at introducing 'Made in' origin marking - in other words, that it will once again be blocked by the Council.', 'ro': 'Acum ne temem cÄƒ, dacÄƒ sfera de aplicare a directivei va fi extinsÄƒ, aceasta va avea exact aceeaÅŸi soartÄƒ ca ultima Ã®ncercare de introducere a marcajului de origine "Made inâ€, cu alte cuvinte, cÄƒ va fi din nou blocatÄƒ la Consiliu.'}</td>
    </tr>
    <tr>
      <th>4</th>
      <td>{'en': 'The country dropped nine slots to 85th, with a score of 6.58.', 'ro': 'Å¢ara a coborÃ¢t nouÄƒ poziÅ£ii, pe locul 85, cu un scor de 6,58.'}</td>
    </tr>
  </tbody>
</table>


<p>metricæ˜¯<a href="https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Metric" target="_blank"><code>datasets.Metric</code></a>ç±»çš„ä¸€ä¸ªå®ä¾‹ï¼ŒæŸ¥çœ‹metricå’Œä½¿ç”¨çš„ä¾‹å­:</p>
<pre><code class="lang-python">metric
</code></pre>
<pre><code>Metric(name: "sacrebleu", features: {'predictions': Value(dtype='string', id='sequence'), 'references': Sequence(feature=Value(dtype='string', id='sequence'), length=-1, id='references')}, usage: """
Produces BLEU scores along with its sufficient statistics
from a source against one or more references.

Args:
    predictions: The system stream (a sequence of segments)
    references: A list of one or more reference streams (each a sequence of segments)
    smooth: The smoothing method to use
    smooth_value: For 'floor' smoothing, the floor to use
    force: Ignore data that looks already tokenized
    lowercase: Lowercase the data
    tokenize: The tokenizer to use
Returns:
    'score': BLEU score,
    'counts': Counts,
    'totals': Totals,
    'precisions': Precisions,
    'bp': Brevity penalty,
    'sys_len': predictions length,
    'ref_len': reference length,
Examples:

    &gt;&gt;&gt; predictions = ["hello there general kenobi", "foo bar foobar"]
    &gt;&gt;&gt; references = [["hello there general kenobi", "hello there !"], ["foo bar foobar", "foo bar foobar"]]
    &gt;&gt;&gt; sacrebleu = datasets.load_metric("sacrebleu")
    &gt;&gt;&gt; results = sacrebleu.compute(predictions=predictions, references=references)
    &gt;&gt;&gt; print(list(results.keys()))
    ['score', 'counts', 'totals', 'precisions', 'bp', 'sys_len', 'ref_len']
    &gt;&gt;&gt; print(round(results["score"], 1))
    100.0
""", stored examples: 0)
</code></pre><p>æˆ‘ä»¬ä½¿ç”¨<code>compute</code>æ–¹æ³•æ¥å¯¹æ¯”predictionså’Œlabelsï¼Œä»è€Œè®¡ç®—å¾—åˆ†ã€‚predictionså’Œlabelséƒ½éœ€è¦æ˜¯ä¸€ä¸ªlistã€‚å…·ä½“æ ¼å¼è§ä¸‹é¢çš„ä¾‹å­ï¼š</p>
<pre><code class="lang-python">fake_preds = [<span class="hljs-string">"hello there"</span>, <span class="hljs-string">"general kenobi"</span>]
fake_labels = [[<span class="hljs-string">"hello there"</span>], [<span class="hljs-string">"general kenobi"</span>]]
metric.compute(predictions=fake_preds, references=fake_labels)
</code></pre>
<pre><code>{'score': 0.0,
 'counts': [4, 2, 0, 0],
 'totals': [4, 2, 0, 0],
 'precisions': [100.0, 100.0, 0.0, 0.0],
 'bp': 1.0,
 'sys_len': 4,
 'ref_len': 4}
</code></pre><h2 id="æ•°æ®é¢„å¤„ç†">æ•°æ®é¢„å¤„ç†</h2>
<p>åœ¨å°†æ•°æ®å–‚å…¥æ¨¡å‹ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦å¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†ã€‚é¢„å¤„ç†çš„å·¥å…·å«Tokenizerã€‚Tokenizeré¦–å…ˆå¯¹è¾“å…¥è¿›è¡Œtokenizeï¼Œç„¶åå°†tokensè½¬åŒ–ä¸ºé¢„æ¨¡å‹ä¸­éœ€è¦å¯¹åº”çš„token IDï¼Œå†è½¬åŒ–ä¸ºæ¨¡å‹éœ€è¦çš„è¾“å…¥æ ¼å¼ã€‚</p>
<p>ä¸ºäº†è¾¾åˆ°æ•°æ®é¢„å¤„ç†çš„ç›®çš„ï¼Œæˆ‘ä»¬ä½¿ç”¨AutoTokenizer.from_pretrainedæ–¹æ³•å®ä¾‹åŒ–æˆ‘ä»¬çš„tokenizerï¼Œè¿™æ ·å¯ä»¥ç¡®ä¿ï¼š</p>
<ul>
<li>æˆ‘ä»¬å¾—åˆ°ä¸€ä¸ªä¸é¢„è®­ç»ƒæ¨¡å‹ä¸€ä¸€å¯¹åº”çš„tokenizerã€‚</li>
<li>ä½¿ç”¨æŒ‡å®šçš„æ¨¡å‹checkpointå¯¹åº”çš„tokenizerçš„æ—¶å€™ï¼Œæˆ‘ä»¬ä¹Ÿä¸‹è½½äº†æ¨¡å‹éœ€è¦çš„è¯è¡¨åº“vocabularyï¼Œå‡†ç¡®æ¥è¯´æ˜¯tokens vocabularyã€‚</li>
</ul>
<p>è¿™ä¸ªè¢«ä¸‹è½½çš„tokens vocabularyä¼šè¢«ç¼“å­˜èµ·æ¥ï¼Œä»è€Œå†æ¬¡ä½¿ç”¨çš„æ—¶å€™ä¸ä¼šé‡æ–°ä¸‹è½½ã€‚</p>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer
<span class="hljs-comment"># éœ€è¦å®‰è£…`sentencepiece`ï¼š pip install sentencepiece</span>

tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)
</code></pre>
<pre><code>Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.13k/1.13k [00:00&lt;00:00, 466kB/s]
Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 789k/789k [00:00&lt;00:00, 882kB/s]
Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 817k/817k [00:00&lt;00:00, 902kB/s]
Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.39M/1.39M [00:01&lt;00:00, 1.24MB/s]
Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 42.0/42.0 [00:00&lt;00:00, 14.6kB/s]
</code></pre><p>ä»¥æˆ‘ä»¬ä½¿ç”¨çš„mBARTæ¨¡å‹ä¸ºä¾‹ï¼Œæˆ‘ä»¬éœ€è¦æ­£ç¡®è®¾ç½®sourceè¯­è¨€å’Œtargetè¯­è¨€ã€‚å¦‚æœæ‚¨è¦ç¿»è¯‘çš„æ˜¯å…¶ä»–åŒè¯­è¯­æ–™ï¼Œè¯·æŸ¥çœ‹<a href="https://huggingface.co/facebook/mbart-large-cc25" target="_blank">è¿™é‡Œ</a>ã€‚æˆ‘ä»¬å¯ä»¥æ£€æŸ¥sourceå’Œtargetè¯­è¨€çš„è®¾ç½®ï¼š</p>
<pre><code class="lang-python"><span class="hljs-keyword">if</span> <span class="hljs-string">"mbart"</span> <span class="hljs-keyword">in</span> model_checkpoint:
    tokenizer.src_lang = <span class="hljs-string">"en-XX"</span>
    tokenizer.tgt_lang = <span class="hljs-string">"ro-RO"</span>
</code></pre>
<p>tokenizeræ—¢å¯ä»¥å¯¹å•ä¸ªæ–‡æœ¬è¿›è¡Œé¢„å¤„ç†ï¼Œä¹Ÿå¯ä»¥å¯¹ä¸€å¯¹æ–‡æœ¬è¿›è¡Œé¢„å¤„ç†ï¼Œtokenizeré¢„å¤„ç†åå¾—åˆ°çš„æ•°æ®æ»¡è¶³é¢„è®­ç»ƒæ¨¡å‹è¾“å…¥æ ¼å¼</p>
<pre><code class="lang-python">tokenizer(<span class="hljs-string">"Hello, this one sentence!"</span>)
</code></pre>
<pre><code>{'input_ids': [125, 778, 3, 63, 141, 9191, 23, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}
</code></pre><p>ä¸Šé¢çœ‹åˆ°çš„token IDsä¹Ÿå°±æ˜¯input_idsä¸€èˆ¬æ¥è¯´éšç€é¢„è®­ç»ƒæ¨¡å‹åå­—çš„ä¸åŒè€Œæœ‰æ‰€ä¸åŒã€‚åŸå› æ˜¯ä¸åŒçš„é¢„è®­ç»ƒæ¨¡å‹åœ¨é¢„è®­ç»ƒçš„æ—¶å€™è®¾å®šäº†ä¸åŒçš„è§„åˆ™ã€‚ä½†åªè¦tokenizerå’Œmodelçš„åå­—ä¸€è‡´ï¼Œé‚£ä¹ˆtokenizeré¢„å¤„ç†çš„è¾“å…¥æ ¼å¼å°±ä¼šæ»¡è¶³modeléœ€æ±‚çš„ã€‚å…³äºé¢„å¤„ç†æ›´å¤šå†…å®¹å‚è€ƒ<a href="https://huggingface.co/transformers/preprocessing.html" target="_blank">è¿™ä¸ªæ•™ç¨‹</a></p>
<p>é™¤äº†å¯ä»¥tokenizeä¸€å¥è¯ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥tokenizeä¸€ä¸ªlistçš„å¥å­ã€‚</p>
<pre><code class="lang-python">tokenizer([<span class="hljs-string">"Hello, this one sentence!"</span>, <span class="hljs-string">"This is another sentence."</span>])
</code></pre>
<pre><code>{'input_ids': [[125, 778, 3, 63, 141, 9191, 23, 0], [187, 32, 716, 9191, 2, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1]]}
</code></pre><p>æ³¨æ„ï¼šä¸ºäº†ç»™æ¨¡å‹å‡†å¤‡å¥½ç¿»è¯‘çš„targetsï¼Œæˆ‘ä»¬ä½¿ç”¨<code>as_target_tokenizer</code>æ¥æ§åˆ¶targetsæ‰€å¯¹åº”çš„ç‰¹æ®Štokenï¼š</p>
<pre><code class="lang-python"><span class="hljs-keyword">with</span> tokenizer.as_target_tokenizer():
    <span class="hljs-built_in">print</span>(tokenizer(<span class="hljs-string">"Hello, this one sentence!"</span>))
    model_input = tokenizer(<span class="hljs-string">"Hello, this one sentence!"</span>)
    tokens = tokenizer.convert_ids_to_tokens(model_input[<span class="hljs-string">'input_ids'</span>])
    <span class="hljs-comment"># æ‰“å°çœ‹ä¸€ä¸‹special toke</span>
    <span class="hljs-built_in">print</span>(<span class="hljs-string">'tokens: {}'</span>.<span class="hljs-built_in">format</span>(tokens))
</code></pre>
<pre><code>{'input_ids': [10334, 1204, 3, 15, 8915, 27, 452, 59, 29579, 581, 23, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
tokens: ['â–Hel', 'lo', ',', 'â–', 'this', 'â–o', 'ne', 'â–se', 'nten', 'ce', '!', '&lt;/s&gt;']
</code></pre><p>å¦‚æœæ‚¨ä½¿ç”¨çš„æ˜¯T5é¢„è®­ç»ƒæ¨¡å‹çš„checkpointsï¼Œéœ€è¦å¯¹ç‰¹æ®Šçš„å‰ç¼€è¿›è¡Œæ£€æŸ¥ã€‚T5ä½¿ç”¨ç‰¹æ®Šçš„å‰ç¼€æ¥å‘Šè¯‰æ¨¡å‹å…·ä½“è¦åšçš„ä»»åŠ¡ï¼Œå…·ä½“å‰ç¼€ä¾‹å­å¦‚ä¸‹ï¼š</p>
<pre><code class="lang-python"><span class="hljs-keyword">if</span> model_checkpoint <span class="hljs-keyword">in</span> [<span class="hljs-string">"t5-small"</span>, <span class="hljs-string">"t5-base"</span>, <span class="hljs-string">"t5-larg"</span>, <span class="hljs-string">"t5-3b"</span>, <span class="hljs-string">"t5-11b"</span>]:
    prefix = <span class="hljs-string">"translate English to Romanian: "</span>
<span class="hljs-keyword">else</span>:
    prefix = <span class="hljs-string">""</span>
</code></pre>
<p>ç°åœ¨æˆ‘ä»¬å¯ä»¥æŠŠæ‰€æœ‰å†…å®¹æ”¾åœ¨ä¸€èµ·ç»„æˆæˆ‘ä»¬çš„é¢„å¤„ç†å‡½æ•°äº†ã€‚æˆ‘ä»¬å¯¹æ ·æœ¬è¿›è¡Œé¢„å¤„ç†çš„æ—¶å€™ï¼Œæˆ‘ä»¬è¿˜ä¼š<code>truncation=True</code>è¿™ä¸ªå‚æ•°æ¥ç¡®ä¿æˆ‘ä»¬è¶…é•¿çš„å¥å­è¢«æˆªæ–­ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œå¯¹ä¸æ¯”è¾ƒçŸ­çš„å¥å­æˆ‘ä»¬ä¼šè‡ªåŠ¨paddingã€‚</p>
<pre><code class="lang-python">max_input_length = <span class="hljs-number">128</span>
max_target_length = <span class="hljs-number">128</span>
source_lang = <span class="hljs-string">"en"</span>
target_lang = <span class="hljs-string">"ro"</span>

<span class="hljs-keyword">def</span> <span class="hljs-title function_">preprocess_function</span>(<span class="hljs-params">examples</span>):
    inputs = [prefix + ex[source_lang] <span class="hljs-keyword">for</span> ex <span class="hljs-keyword">in</span> examples[<span class="hljs-string">"translation"</span>]]
    targets = [ex[target_lang] <span class="hljs-keyword">for</span> ex <span class="hljs-keyword">in</span> examples[<span class="hljs-string">"translation"</span>]]
    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=<span class="hljs-literal">True</span>)

    <span class="hljs-comment"># Setup the tokenizer for targets</span>
    <span class="hljs-keyword">with</span> tokenizer.as_target_tokenizer():
        labels = tokenizer(targets, max_length=max_target_length, truncation=<span class="hljs-literal">True</span>)

    model_inputs[<span class="hljs-string">"labels"</span>] = labels[<span class="hljs-string">"input_ids"</span>]
    <span class="hljs-keyword">return</span> model_inputs
</code></pre>
<p>ä»¥ä¸Šçš„é¢„å¤„ç†å‡½æ•°å¯ä»¥å¤„ç†ä¸€ä¸ªæ ·æœ¬ï¼Œä¹Ÿå¯ä»¥å¤„ç†å¤šä¸ªæ ·æœ¬exapmlesã€‚å¦‚æœæ˜¯å¤„ç†å¤šä¸ªæ ·æœ¬ï¼Œåˆ™è¿”å›çš„æ˜¯å¤šä¸ªæ ·æœ¬è¢«é¢„å¤„ç†ä¹‹åçš„ç»“æœlistã€‚</p>
<pre><code class="lang-python">preprocess_function(raw_datasets[<span class="hljs-string">'train'</span>][:<span class="hljs-number">2</span>])
</code></pre>
<pre><code>{'input_ids': [[393, 4462, 14, 1137, 53, 216, 28636, 0], [24385, 14, 28636, 14, 4646, 4622, 53, 216, 28636, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[42140, 494, 1750, 53, 8, 59, 903, 3543, 9, 15202, 0], [36199, 6612, 9, 15202, 122, 568, 35788, 21549, 53, 8, 59, 903, 3543, 9, 15202, 0]]}
</code></pre><p>æ¥ä¸‹æ¥å¯¹æ•°æ®é›†datasetsé‡Œé¢çš„æ‰€æœ‰æ ·æœ¬è¿›è¡Œé¢„å¤„ç†ï¼Œå¤„ç†çš„æ–¹å¼æ˜¯ä½¿ç”¨mapå‡½æ•°ï¼Œå°†é¢„å¤„ç†å‡½æ•°prepare_train_featuresåº”ç”¨åˆ°ï¼ˆmap)æ‰€æœ‰æ ·æœ¬ä¸Šã€‚</p>
<pre><code class="lang-python">tokenized_datasets = raw_datasets.<span class="hljs-built_in">map</span>(preprocess_function, batched=<span class="hljs-literal">True</span>)
</code></pre>
<pre><code>100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 611/611 [02:32&lt;00:00,  3.99ba/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00&lt;00:00,  3.76ba/s]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00&lt;00:00,  3.89ba/s]
</code></pre><p>æ›´å¥½çš„æ˜¯ï¼Œè¿”å›çš„ç»“æœä¼šè‡ªåŠ¨è¢«ç¼“å­˜ï¼Œé¿å…ä¸‹æ¬¡å¤„ç†çš„æ—¶å€™é‡æ–°è®¡ç®—ï¼ˆä½†æ˜¯ä¹Ÿè¦æ³¨æ„ï¼Œå¦‚æœè¾“å…¥æœ‰æ”¹åŠ¨ï¼Œå¯èƒ½ä¼šè¢«ç¼“å­˜å½±å“ï¼ï¼‰ã€‚datasetsåº“å‡½æ•°ä¼šå¯¹è¾“å…¥çš„å‚æ•°è¿›è¡Œæ£€æµ‹ï¼Œåˆ¤æ–­æ˜¯å¦æœ‰å˜åŒ–ï¼Œå¦‚æœæ²¡æœ‰å˜åŒ–å°±ä½¿ç”¨ç¼“å­˜æ•°æ®ï¼Œå¦‚æœæœ‰å˜åŒ–å°±é‡æ–°å¤„ç†ã€‚ä½†å¦‚æœè¾“å…¥å‚æ•°ä¸å˜ï¼Œæƒ³æ”¹å˜è¾“å…¥çš„æ—¶å€™ï¼Œæœ€å¥½æ¸…ç†è°ƒè¿™ä¸ªç¼“å­˜ã€‚æ¸…ç†çš„æ–¹å¼æ˜¯ä½¿ç”¨<code>load_from_cache_file=False</code>å‚æ•°ã€‚å¦å¤–ï¼Œä¸Šé¢ä½¿ç”¨åˆ°çš„<code>batched=True</code>è¿™ä¸ªå‚æ•°æ˜¯tokenizerçš„ç‰¹ç‚¹ï¼Œä»¥ä¸ºè¿™ä¼šä½¿ç”¨å¤šçº¿ç¨‹åŒæ—¶å¹¶è¡Œå¯¹è¾“å…¥è¿›è¡Œå¤„ç†ã€‚</p>
<h2 id="å¾®è°ƒtransformeræ¨¡å‹">å¾®è°ƒtransformeræ¨¡å‹</h2>
<p>æ—¢ç„¶æ•°æ®å·²ç»å‡†å¤‡å¥½äº†ï¼Œç°åœ¨æˆ‘ä»¬éœ€è¦ä¸‹è½½å¹¶åŠ è½½æˆ‘ä»¬çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œç„¶åå¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹ã€‚æ—¢ç„¶æˆ‘ä»¬æ˜¯åšseq2seqä»»åŠ¡ï¼Œé‚£ä¹ˆæˆ‘ä»¬éœ€è¦ä¸€ä¸ªèƒ½è§£å†³è¿™ä¸ªä»»åŠ¡çš„æ¨¡å‹ç±»ã€‚æˆ‘ä»¬ä½¿ç”¨<code>AutoModelForSeq2SeqLM</code>è¿™ä¸ªç±»ã€‚å’Œtokenizerç›¸ä¼¼ï¼Œ<code>from_pretrained</code>æ–¹æ³•åŒæ ·å¯ä»¥å¸®åŠ©æˆ‘ä»¬ä¸‹è½½å¹¶åŠ è½½æ¨¡å‹ï¼ŒåŒæ—¶ä¹Ÿä¼šå¯¹æ¨¡å‹è¿›è¡Œç¼“å­˜ï¼Œå°±ä¸ä¼šé‡å¤ä¸‹è½½æ¨¡å‹å•¦ã€‚</p>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer

model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)
</code></pre>
<pre><code>Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 301M/301M [00:19&lt;00:00, 15.1MB/s]
</code></pre><p>ç”±äºæˆ‘ä»¬å¾®è°ƒçš„ä»»åŠ¡æ˜¯æœºå™¨ç¿»è¯‘ï¼Œè€Œæˆ‘ä»¬åŠ è½½çš„æ˜¯é¢„è®­ç»ƒçš„seq2seqæ¨¡å‹ï¼Œæ‰€ä»¥ä¸ä¼šæç¤ºæˆ‘ä»¬åŠ è½½æ¨¡å‹çš„æ—¶å€™æ‰”æ‰äº†ä¸€äº›ä¸åŒ¹é…çš„ç¥ç»ç½‘ç»œå‚æ•°ï¼ˆæ¯”å¦‚ï¼šé¢„è®­ç»ƒè¯­è¨€æ¨¡å‹çš„ç¥ç»ç½‘ç»œheadè¢«æ‰”æ‰äº†ï¼ŒåŒæ—¶éšæœºåˆå§‹åŒ–äº†æœºå™¨ç¿»è¯‘çš„ç¥ç»ç½‘ç»œheadï¼‰ã€‚</p>
<p>ä¸ºäº†èƒ½å¤Ÿå¾—åˆ°ä¸€ä¸ª<code>Seq2SeqTrainer</code>è®­ç»ƒå·¥å…·ï¼Œæˆ‘ä»¬è¿˜éœ€è¦3ä¸ªè¦ç´ ï¼Œå…¶ä¸­æœ€é‡è¦çš„æ˜¯è®­ç»ƒçš„è®¾å®š/å‚æ•°<a href="https://huggingface.co/transformers/main_classes/trainer.html#transformers.Seq2SeqTrainingArguments" target="_blank"><code>Seq2SeqTrainingArguments</code></a>ã€‚è¿™ä¸ªè®­ç»ƒè®¾å®šåŒ…å«äº†èƒ½å¤Ÿå®šä¹‰è®­ç»ƒè¿‡ç¨‹çš„æ‰€æœ‰å±æ€§</p>
<pre><code class="lang-python">batch_size = <span class="hljs-number">16</span>
args = Seq2SeqTrainingArguments(
    <span class="hljs-string">"test-translation"</span>,
    evaluation_strategy = <span class="hljs-string">"epoch"</span>,
    learning_rate=<span class="hljs-number">2e-5</span>,
    per_device_train_batch_size=batch_size,
    per_device_eval_batch_size=batch_size,
    weight_decay=<span class="hljs-number">0.01</span>,
    save_total_limit=<span class="hljs-number">3</span>,
    num_train_epochs=<span class="hljs-number">1</span>,
    predict_with_generate=<span class="hljs-literal">True</span>,
    fp16=<span class="hljs-literal">False</span>,
)
</code></pre>
<p>ä¸Šé¢evaluation_strategy = "epoch"å‚æ•°å‘Šè¯‰è®­ç»ƒä»£ç ï¼šæˆ‘ä»¬æ¯ä¸ªepcohä¼šåšä¸€æ¬¡éªŒè¯è¯„ä¼°ã€‚</p>
<p>ä¸Šé¢batch_sizeåœ¨è¿™ä¸ªnotebookä¹‹å‰å®šä¹‰å¥½äº†ã€‚</p>
<p>ç”±äºæˆ‘ä»¬çš„æ•°æ®é›†æ¯”è¾ƒå¤§ï¼ŒåŒæ—¶<code>Seq2SeqTrainer</code>ä¼šä¸æ–­ä¿å­˜æ¨¡å‹ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦å‘Šè¯‰å®ƒè‡³å¤šä¿å­˜<code>save_total_limit=3</code>ä¸ªæ¨¡å‹ã€‚</p>
<p>æœ€åæˆ‘ä»¬éœ€è¦ä¸€ä¸ªæ•°æ®æ”¶é›†å™¨data collatorï¼Œå°†æˆ‘ä»¬å¤„ç†å¥½çš„è¾“å…¥å–‚ç»™æ¨¡å‹ã€‚</p>
<pre><code class="lang-python">data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)
</code></pre>
<p>è®¾ç½®å¥½<code>Seq2SeqTrainer</code>è¿˜å‰©æœ€åä¸€ä»¶äº‹æƒ…ï¼Œé‚£å°±æ˜¯æˆ‘ä»¬éœ€è¦å®šä¹‰å¥½è¯„ä¼°æ–¹æ³•ã€‚æˆ‘ä»¬ä½¿ç”¨<code>metric</code>æ¥å®Œæˆè¯„ä¼°ã€‚å°†æ¨¡å‹é¢„æµ‹é€å…¥è¯„ä¼°ä¹‹å‰ï¼Œæˆ‘ä»¬ä¹Ÿä¼šåšä¸€äº›æ•°æ®åå¤„ç†ï¼š</p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

<span class="hljs-keyword">def</span> <span class="hljs-title function_">postprocess_text</span>(<span class="hljs-params">preds, labels</span>):
    preds = [pred.strip() <span class="hljs-keyword">for</span> pred <span class="hljs-keyword">in</span> preds]
    labels = [[label.strip()] <span class="hljs-keyword">for</span> label <span class="hljs-keyword">in</span> labels]

    <span class="hljs-keyword">return</span> preds, labels

<span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_metrics</span>(<span class="hljs-params">eval_preds</span>):
    preds, labels = eval_preds
    <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(preds, <span class="hljs-built_in">tuple</span>):
        preds = preds[<span class="hljs-number">0</span>]
    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=<span class="hljs-literal">True</span>)

    <span class="hljs-comment"># Replace -100 in the labels as we can't decode them.</span>
    labels = np.where(labels != -<span class="hljs-number">100</span>, labels, tokenizer.pad_token_id)
    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=<span class="hljs-literal">True</span>)

    <span class="hljs-comment"># Some simple post-processing</span>
    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)

    result = metric.compute(predictions=decoded_preds, references=decoded_labels)
    result = {<span class="hljs-string">"bleu"</span>: result[<span class="hljs-string">"score"</span>]}

    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) <span class="hljs-keyword">for</span> pred <span class="hljs-keyword">in</span> preds]
    result[<span class="hljs-string">"gen_len"</span>] = np.mean(prediction_lens)
    result = {k: <span class="hljs-built_in">round</span>(v, <span class="hljs-number">4</span>) <span class="hljs-keyword">for</span> k, v <span class="hljs-keyword">in</span> result.items()}
    <span class="hljs-keyword">return</span> result
</code></pre>
<p>æœ€åå°†æ‰€æœ‰çš„å‚æ•°/æ•°æ®/æ¨¡å‹ä¼ ç»™<code>Seq2SeqTrainer</code>å³å¯</p>
<pre><code class="lang-python">trainer = Seq2SeqTrainer(
    model,
    args,
    train_dataset=tokenized_datasets[<span class="hljs-string">"train"</span>],
    eval_dataset=tokenized_datasets[<span class="hljs-string">"validation"</span>],
    data_collator=data_collator,
    tokenizer=tokenizer,
    compute_metrics=compute_metrics
)
</code></pre>
<p>è°ƒç”¨<code>train</code>æ–¹æ³•è¿›è¡Œå¾®è°ƒè®­ç»ƒã€‚</p>
<pre><code class="lang-python">trainer.train()
</code></pre>
<p>æœ€ååˆ«å¿˜äº†ï¼ŒæŸ¥çœ‹å¦‚ä½•ä¸Šä¼ æ¨¡å‹ ï¼Œä¸Šä¼ æ¨¡å‹åˆ°](<a href="https://huggingface.co/transformers/model_sharing.html" target="_blank">https://huggingface.co/transformers/model_sharing.html</a>) åˆ°<a href="https://huggingface.co/models" target="_blank">ğŸ¤— Model Hub</a>ã€‚éšåæ‚¨å°±å¯ä»¥åƒè¿™ä¸ªnotebookä¸€å¼€å§‹ä¸€æ ·ï¼Œç›´æ¥ç”¨æ¨¡å‹åå­—å°±èƒ½ä½¿ç”¨æ‚¨çš„æ¨¡å‹å•¦ã€‚</p>
<pre><code class="lang-python">

</code></pre>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="4.5-ç”Ÿæˆä»»åŠ¡-è¯­è¨€æ¨¡å‹.html" class="navigation navigation-prev " aria-label="Previous page: 4.5-ç”Ÿæˆä»»åŠ¡-è¯­è¨€æ¨¡å‹">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="4.7-ç”Ÿæˆä»»åŠ¡-æ‘˜è¦ç”Ÿæˆ.html" class="navigation navigation-next " aria-label="Next page: 4.7-ç”Ÿæˆä»»åŠ¡-æ‘˜è¦ç”Ÿæˆ">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"4.6-ç”Ÿæˆä»»åŠ¡-æœºå™¨ç¿»è¯‘","level":"4.8","depth":1,"next":{"title":"4.7-ç”Ÿæˆä»»åŠ¡-æ‘˜è¦ç”Ÿæˆ","level":"4.9","depth":1,"path":"ç¯‡ç« 4-ä½¿ç”¨Transformersè§£å†³NLPä»»åŠ¡/4.7-ç”Ÿæˆä»»åŠ¡-æ‘˜è¦ç”Ÿæˆ.md","ref":"./ç¯‡ç« 4-ä½¿ç”¨Transformersè§£å†³NLPä»»åŠ¡/4.7-ç”Ÿæˆä»»åŠ¡-æ‘˜è¦ç”Ÿæˆ.md","articles":[]},"previous":{"title":"4.5-ç”Ÿæˆä»»åŠ¡-è¯­è¨€æ¨¡å‹","level":"4.7","depth":1,"path":"ç¯‡ç« 4-ä½¿ç”¨Transformersè§£å†³NLPä»»åŠ¡/4.5-ç”Ÿæˆä»»åŠ¡-è¯­è¨€æ¨¡å‹.md","ref":"./ç¯‡ç« 4-ä½¿ç”¨Transformersè§£å†³NLPä»»åŠ¡/4.5-ç”Ÿæˆä»»åŠ¡-è¯­è¨€æ¨¡å‹.md","articles":[]},"dir":"ltr"},"config":{"gitbook":"*","theme":"default","variables":{},"plugins":["livereload"],"pluginsConfig":{"livereload":{},"highlight":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56},"embedFonts":false},"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"}},"file":{"path":"ç¯‡ç« 4-ä½¿ç”¨Transformersè§£å†³NLPä»»åŠ¡/4.6-ç”Ÿæˆä»»åŠ¡-æœºå™¨ç¿»è¯‘.md","mtime":"2024-08-23T15:34:37.404Z","type":"markdown"},"gitbook":{"version":"5.1.4","time":"2024-08-23T15:50:04.957Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <noscript>
        <style>
            .honkit-cloak {
                display: block !important;
            }
        </style>
    </noscript>
    <script>
        // Restore sidebar state as critical path for prevent layout shift
        function __init__getSidebarState(defaultValue){
            var baseKey = "";
            var key = baseKey + ":sidebar";
            try {
                var value = localStorage[key];
                if (value === undefined) {
                    return defaultValue;
                }
                var parsed = JSON.parse(value);
                return parsed == null ? defaultValue : parsed;
            } catch (e) {
                return defaultValue;
            }
        }
        function __init__restoreLastSidebarState() {
            var isMobile = window.matchMedia("(max-width: 600px)").matches;
            if (isMobile) {
                // Init last state if not mobile
                return;
            }
            var sidebarState = __init__getSidebarState(true);
            var book = document.querySelector(".book");
            // Show sidebar if it enabled
            if (sidebarState && book) {
                book.classList.add("without-animation", "with-summary");
            }
        }

        try {
            __init__restoreLastSidebarState();
        } finally {
            var book = document.querySelector(".book");
            book.classList.remove("honkit-cloak");
        }
    </script>
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="../gitbook/gitbook-plugin-livereload/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

