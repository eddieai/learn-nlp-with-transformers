
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <title>4.1-æ–‡æœ¬åˆ†ç±» Â· HonKit</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="HonKit 5.1.4">
        
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/@honkit/honkit-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=3, user-scalable=yes">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="4.2-åºåˆ—æ ‡æ³¨.html" />
    
    
    <link rel="prev" href="4.0-åŸºäºHuggingFace-Transformersçš„é¢„è®­ç»ƒæ¨¡å‹å¾®è°ƒ.html" />
    

    </head>
    <body>
        
<div class="book honkit-cloak">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        <li class="header">ç¯‡ç« 1-å‰è¨€</li>
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="../ç¯‡ç« 1-å‰è¨€/1.0-æœ¬åœ°é˜…è¯»å’Œä»£ç è¿è¡Œç¯å¢ƒé…ç½®.html">
            
                <a href="../ç¯‡ç« 1-å‰è¨€/1.0-æœ¬åœ°é˜…è¯»å’Œä»£ç è¿è¡Œç¯å¢ƒé…ç½®.html">
            
                    
                    1.0-æœ¬åœ°é˜…è¯»å’Œä»£ç è¿è¡Œç¯å¢ƒé…ç½®
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="../ç¯‡ç« 1-å‰è¨€/1.1-Transformersåœ¨NLPä¸­çš„å…´èµ·.html">
            
                <a href="../ç¯‡ç« 1-å‰è¨€/1.1-Transformersåœ¨NLPä¸­çš„å…´èµ·.html">
            
                    
                    1.1-Transformersåœ¨NLPä¸­çš„å…´èµ·
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">ç¯‡ç« 2-Transformerç›¸å…³åŸç†</li>
        
        
    
        <li class="chapter " data-level="2.1" data-path="../ç¯‡ç« 2-Transformerç›¸å…³åŸç†/2.0-å‰è¨€.html">
            
                <a href="../ç¯‡ç« 2-Transformerç›¸å…³åŸç†/2.0-å‰è¨€.html">
            
                    
                    2.0-å‰è¨€
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.2" data-path="../ç¯‡ç« 2-Transformerç›¸å…³åŸç†/2.1-å›¾è§£attention.html">
            
                <a href="../ç¯‡ç« 2-Transformerç›¸å…³åŸç†/2.1-å›¾è§£attention.html">
            
                    
                    2.1-å›¾è§£attention
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.3" data-path="../ç¯‡ç« 2-Transformerç›¸å…³åŸç†/2.2-å›¾è§£transformer.html">
            
                <a href="../ç¯‡ç« 2-Transformerç›¸å…³åŸç†/2.2-å›¾è§£transformer.html">
            
                    
                    2.2-å›¾è§£transformer
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.4" data-path="../ç¯‡ç« 2-Transformerç›¸å…³åŸç†/2.2.1-Pytorchç¼–å†™Transformer.html">
            
                <a href="../ç¯‡ç« 2-Transformerç›¸å…³åŸç†/2.2.1-Pytorchç¼–å†™Transformer.html">
            
                    
                    2.2.1-Pytorchç¼–å†™Transformer
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.5" data-path="../ç¯‡ç« 2-Transformerç›¸å…³åŸç†/2.2.1-Pytorchç¼–å†™Transformer-é€‰è¯».md">
            
                <span>
            
                    
                    2.2.2-Pytorchç¼–å†™Transformer-é€‰è¯»
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.6" data-path="../ç¯‡ç« 2-Transformerç›¸å…³åŸç†/2.3-å›¾è§£BERT.html">
            
                <a href="../ç¯‡ç« 2-Transformerç›¸å…³åŸç†/2.3-å›¾è§£BERT.html">
            
                    
                    2.3-å›¾è§£BERT
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.7" data-path="../ç¯‡ç« 2-Transformerç›¸å…³åŸç†/2.4-å›¾è§£GPT.html">
            
                <a href="../ç¯‡ç« 2-Transformerç›¸å…³åŸç†/2.4-å›¾è§£GPT.html">
            
                    
                    2.4-å›¾è§£GPT
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.8" data-path="../ç¯‡ç« 2-Transformerç›¸å…³åŸç†/2.5-ç¯‡ç« å°æµ‹.html">
            
                <a href="../ç¯‡ç« 2-Transformerç›¸å…³åŸç†/2.5-ç¯‡ç« å°æµ‹.html">
            
                    
                    2.5-ç¯‡ç« å°æµ‹
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">ç¯‡ç« 3-ç¼–å†™ä¸€ä¸ªTransformeræ¨¡å‹ï¼šBERT</li>
        
        
    
        <li class="chapter " data-level="3.1" data-path="../ç¯‡ç« 3-ç¼–å†™ä¸€ä¸ªTransformeræ¨¡å‹ï¼šBERT/3.1-å¦‚ä½•å®ç°ä¸€ä¸ªBERT.html">
            
                <a href="../ç¯‡ç« 3-ç¼–å†™ä¸€ä¸ªTransformeræ¨¡å‹ï¼šBERT/3.1-å¦‚ä½•å®ç°ä¸€ä¸ªBERT.html">
            
                    
                    3.1-å¦‚ä½•å®ç°ä¸€ä¸ªBERT
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.2" data-path="../ç¯‡ç« 3-ç¼–å†™ä¸€ä¸ªTransformeræ¨¡å‹ï¼šBERT/3.2-å¦‚ä½•åº”ç”¨ä¸€ä¸ªBERT.html">
            
                <a href="../ç¯‡ç« 3-ç¼–å†™ä¸€ä¸ªTransformeræ¨¡å‹ï¼šBERT/3.2-å¦‚ä½•åº”ç”¨ä¸€ä¸ªBERT.html">
            
                    
                    3.2-å¦‚ä½•åº”ç”¨ä¸€ä¸ªBERT
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.3" data-path="../ç¯‡ç« 3-ç¼–å†™ä¸€ä¸ªTransformeræ¨¡å‹ï¼šBERT/3.3-ç¯‡ç« å°æµ‹.html">
            
                <a href="../ç¯‡ç« 3-ç¼–å†™ä¸€ä¸ªTransformeræ¨¡å‹ï¼šBERT/3.3-ç¯‡ç« å°æµ‹.html">
            
                    
                    3.3-ç¯‡ç« å°æµ‹
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">ç¯‡ç« 4-ä½¿ç”¨Transformersè§£å†³NLPä»»åŠ¡</li>
        
        
    
        <li class="chapter " data-level="4.1" data-path="4.0-å‰è¨€.html">
            
                <a href="4.0-å‰è¨€.html">
            
                    
                    4.0-å‰è¨€
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.2" data-path="4.0-åŸºäºHuggingFace-Transformersçš„é¢„è®­ç»ƒæ¨¡å‹å¾®è°ƒ.html">
            
                <a href="4.0-åŸºäºHuggingFace-Transformersçš„é¢„è®­ç»ƒæ¨¡å‹å¾®è°ƒ.html">
            
                    
                    4.0-åŸºäºHuggingFace-Transformersçš„é¢„è®­ç»ƒæ¨¡å‹å¾®è°ƒ
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="4.3" data-path="4.1-æ–‡æœ¬åˆ†ç±».html">
            
                <a href="4.1-æ–‡æœ¬åˆ†ç±».html">
            
                    
                    4.1-æ–‡æœ¬åˆ†ç±»
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.4" data-path="4.2-åºåˆ—æ ‡æ³¨.html">
            
                <a href="4.2-åºåˆ—æ ‡æ³¨.html">
            
                    
                    4.2-åºåˆ—æ ‡æ³¨
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.5" data-path="4.3-é—®ç­”ä»»åŠ¡-æŠ½å–å¼é—®ç­”.html">
            
                <a href="4.3-é—®ç­”ä»»åŠ¡-æŠ½å–å¼é—®ç­”.html">
            
                    
                    4.3-é—®ç­”ä»»åŠ¡-æŠ½å–å¼é—®ç­”
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.6" data-path="4.4-é—®ç­”ä»»åŠ¡-å¤šé€‰é—®ç­”.html">
            
                <a href="4.4-é—®ç­”ä»»åŠ¡-å¤šé€‰é—®ç­”.html">
            
                    
                    4.4-é—®ç­”ä»»åŠ¡-å¤šé€‰é—®ç­”
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.7" data-path="4.5-ç”Ÿæˆä»»åŠ¡-è¯­è¨€æ¨¡å‹.html">
            
                <a href="4.5-ç”Ÿæˆä»»åŠ¡-è¯­è¨€æ¨¡å‹.html">
            
                    
                    4.5-ç”Ÿæˆä»»åŠ¡-è¯­è¨€æ¨¡å‹
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.8" data-path="4.6-ç”Ÿæˆä»»åŠ¡-æœºå™¨ç¿»è¯‘.html">
            
                <a href="4.6-ç”Ÿæˆä»»åŠ¡-æœºå™¨ç¿»è¯‘.html">
            
                    
                    4.6-ç”Ÿæˆä»»åŠ¡-æœºå™¨ç¿»è¯‘
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.9" data-path="4.7-ç”Ÿæˆä»»åŠ¡-æ‘˜è¦ç”Ÿæˆ.html">
            
                <a href="4.7-ç”Ÿæˆä»»åŠ¡-æ‘˜è¦ç”Ÿæˆ.html">
            
                    
                    4.7-ç”Ÿæˆä»»åŠ¡-æ‘˜è¦ç”Ÿæˆ
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.10" data-path="4.8-ç¯‡ç« å°æµ‹.html">
            
                <a href="4.8-ç¯‡ç« å°æµ‹.html">
            
                    
                    4.8-ç¯‡ç« å°æµ‹
            
                </a>
            

            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://github.com/honkit/honkit" target="blank" class="gitbook-link">
            Published with HonKit
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >4.1-æ–‡æœ¬åˆ†ç±»</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <p>æœ¬æ–‡æ¶‰åŠçš„jupter notebookåœ¨<a href="https://github.com/datawhalechina/learn-nlp-with-transformers/tree/main/docs/%E7%AF%87%E7%AB%A04-%E4%BD%BF%E7%94%A8Transformers%E8%A7%A3%E5%86%B3NLP%E4%BB%BB%E5%8A%A1" target="_blank">ç¯‡ç« 4ä»£ç åº“ä¸­</a>ã€‚</p>
<p>ä¹Ÿç›´æ¥ä½¿ç”¨google colab notebookæ‰“å¼€æœ¬æ•™ç¨‹ï¼Œä¸‹è½½ç›¸å…³æ•°æ®é›†å’Œæ¨¡å‹ã€‚
å¦‚æœæ‚¨æ­£åœ¨googleçš„colabä¸­æ‰“å¼€è¿™ä¸ªnotebookï¼Œæ‚¨å¯èƒ½éœ€è¦å®‰è£…Transformerså’ŒğŸ¤—Datasetsåº“ã€‚å°†ä»¥ä¸‹å‘½ä»¤å–æ¶ˆæ³¨é‡Šå³å¯å®‰è£…ã€‚</p>
<pre><code class="lang-python">!pip install transformers datasets
</code></pre>
<p>å¦‚æœæ‚¨æ­£åœ¨æœ¬åœ°æ‰“å¼€è¿™ä¸ªnotebookï¼Œè¯·ç¡®ä¿æ‚¨å·²ç»è¿›è¡Œä¸Šè¿°ä¾èµ–åŒ…çš„å®‰è£…ã€‚
æ‚¨ä¹Ÿå¯ä»¥åœ¨<a href="https://github.com/huggingface/transformers/tree/master/examples/text-classification" target="_blank">è¿™é‡Œ</a>æ‰¾åˆ°æœ¬notebookçš„å¤šGPUåˆ†å¸ƒå¼è®­ç»ƒç‰ˆæœ¬ã€‚</p>
<h1 id="å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œæ–‡æœ¬åˆ†ç±»">å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œæ–‡æœ¬åˆ†ç±»</h1>
<p>æˆ‘ä»¬å°†å±•ç¤ºå¦‚ä½•ä½¿ç”¨ <a href="https://github.com/huggingface/transformers" target="_blank">ğŸ¤— Transformers</a>ä»£ç åº“ä¸­çš„æ¨¡å‹æ¥è§£å†³æ–‡æœ¬åˆ†ç±»ä»»åŠ¡ï¼Œä»»åŠ¡æ¥æºäº<a href="https://gluebenchmark.com/" target="_blank">GLUE Benchmark</a>.</p>
<p><img src="https://github.com/huggingface/notebooks/blob/master/examples/images/text_classification.png?raw=1" alt="Widget inference on a text classification task"></img></p>
<p>GLUEæ¦œå•åŒ…å«äº†9ä¸ªå¥å­çº§åˆ«çš„åˆ†ç±»ä»»åŠ¡ï¼Œåˆ†åˆ«æ˜¯ï¼š</p>
<ul>
<li><a href="https://nyu-mll.github.io/CoLA/" target="_blank">CoLA</a> (Corpus of Linguistic Acceptability) é‰´åˆ«ä¸€ä¸ªå¥å­æ˜¯å¦è¯­æ³•æ­£ç¡®.</li>
<li><a href="https://arxiv.org/abs/1704.05426" target="_blank">MNLI</a> (Multi-Genre Natural Language Inference) ç»™å®šä¸€ä¸ªå‡è®¾ï¼Œåˆ¤æ–­å¦ä¸€ä¸ªå¥å­ä¸è¯¥å‡è®¾çš„å…³ç³»ï¼šentails, contradicts æˆ–è€… unrelatedã€‚</li>
<li><a href="https://www.microsoft.com/en-us/download/details.aspx?id=52398" target="_blank">MRPC</a> (Microsoft Research Paraphrase Corpus) åˆ¤æ–­ä¸¤ä¸ªå¥å­æ˜¯å¦äº’ä¸ºparaphrases.</li>
<li><a href="https://rajpurkar.github.io/SQuAD-explorer/" target="_blank">QNLI</a> (Question-answering Natural Language Inference) åˆ¤æ–­ç¬¬2å¥æ˜¯å¦åŒ…å«ç¬¬1å¥é—®é¢˜çš„ç­”æ¡ˆã€‚</li>
<li><a href="https://data.quora.com/First-Quora-Dataset-Release-Question-Pairs" target="_blank">QQP</a> (Quora Question Pairs2) åˆ¤æ–­ä¸¤ä¸ªé—®å¥æ˜¯å¦è¯­ä¹‰ç›¸åŒã€‚</li>
<li><a href="https://aclweb.org/aclwiki/Recognizing_Textual_Entailment" target="_blank">RTE</a> (Recognizing Textual Entailment)åˆ¤æ–­ä¸€ä¸ªå¥å­æ˜¯å¦ä¸å‡è®¾æˆentailå…³ç³»ã€‚</li>
<li><a href="https://nlp.stanford.edu/sentiment/index.html" target="_blank">SST-2</a> (Stanford Sentiment Treebank) åˆ¤æ–­ä¸€ä¸ªå¥å­çš„æƒ…æ„Ÿæ­£è´Ÿå‘.</li>
<li><a href="http://ixa2.si.ehu.es/stswiki/index.php/STSbenchmark" target="_blank">STS-B</a> (Semantic Textual Similarity Benchmark) åˆ¤æ–­ä¸¤ä¸ªå¥å­çš„ç›¸ä¼¼æ€§ï¼ˆåˆ†æ•°ä¸º1-5åˆ†ï¼‰ã€‚</li>
<li><a href="https://cs.nyu.edu/faculty/davise/papers/WinogradSchemas/WS.html" target="_blank">WNLI</a> (Winograd Natural Language Inference) Determine if a sentence with an anonymous pronoun and a sentence with this pronoun replaced are entailed or not. </li>
</ul>
<p>å¯¹äºä»¥ä¸Šä»»åŠ¡ï¼Œæˆ‘ä»¬å°†å±•ç¤ºå¦‚ä½•ä½¿ç”¨ç®€å•çš„Datasetåº“åŠ è½½æ•°æ®é›†ï¼ŒåŒæ—¶ä½¿ç”¨transformerä¸­çš„<code>Trainer</code>æ¥å£å¯¹é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œå¾®è°ƒã€‚</p>
<pre><code class="lang-python">GLUE_TASKS = [<span class="hljs-string">"cola"</span>, <span class="hljs-string">"mnli"</span>, <span class="hljs-string">"mnli-mm"</span>, <span class="hljs-string">"mrpc"</span>, <span class="hljs-string">"qnli"</span>, <span class="hljs-string">"qqp"</span>, <span class="hljs-string">"rte"</span>, <span class="hljs-string">"sst2"</span>, <span class="hljs-string">"stsb"</span>, <span class="hljs-string">"wnli"</span>]
</code></pre>
<p>æœ¬notebookç†è®ºä¸Šå¯ä»¥ä½¿ç”¨å„ç§å„æ ·çš„transformeræ¨¡å‹ï¼ˆ<a href="https://huggingface.co/models" target="_blank">æ¨¡å‹é¢æ¿</a>ï¼‰ï¼Œè§£å†³ä»»ä½•æ–‡æœ¬åˆ†ç±»åˆ†ç±»ä»»åŠ¡ã€‚</p>
<p>å¦‚æœæ‚¨æ‰€å¤„ç†çš„ä»»åŠ¡æœ‰æ‰€ä¸åŒï¼Œå¤§æ¦‚ç‡åªéœ€è¦å¾ˆå°çš„æ”¹åŠ¨ä¾¿å¯ä»¥ä½¿ç”¨æœ¬notebookè¿›è¡Œå¤„ç†ã€‚åŒæ—¶ï¼Œæ‚¨åº”è¯¥æ ¹æ®æ‚¨çš„GPUæ˜¾å­˜æ¥è°ƒæ•´å¾®è°ƒè®­ç»ƒæ‰€éœ€è¦çš„btach sizeå¤§å°ï¼Œé¿å…æ˜¾å­˜æº¢å‡ºã€‚</p>
<pre><code class="lang-python">task = <span class="hljs-string">"cola"</span>
model_checkpoint = <span class="hljs-string">"distilbert-base-uncased"</span>
batch_size = <span class="hljs-number">16</span>
</code></pre>
<h2 id="åŠ è½½æ•°æ®">åŠ è½½æ•°æ®</h2>
<p>æˆ‘ä»¬å°†ä¼šä½¿ç”¨<a href="https://github.com/huggingface/datasets" target="_blank">ğŸ¤— Datasets</a>åº“æ¥åŠ è½½æ•°æ®å’Œå¯¹åº”çš„è¯„æµ‹æ–¹å¼ã€‚æ•°æ®åŠ è½½å’Œè¯„æµ‹æ–¹å¼åŠ è½½åªéœ€è¦ç®€å•ä½¿ç”¨<code>load_dataset</code>å’Œ<code>load_metric</code>å³å¯ã€‚</p>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset, load_metric
</code></pre>
<p>é™¤äº†<code>mnli-mm</code>ä»¥å¤–ï¼Œå…¶ä»–ä»»åŠ¡éƒ½å¯ä»¥ç›´æ¥é€šè¿‡ä»»åŠ¡åå­—è¿›è¡ŒåŠ è½½ã€‚æ•°æ®åŠ è½½ä¹‹åä¼šè‡ªåŠ¨ç¼“å­˜ã€‚</p>
<pre><code class="lang-python">actual_task = <span class="hljs-string">"mnli"</span> <span class="hljs-keyword">if</span> task == <span class="hljs-string">"mnli-mm"</span> <span class="hljs-keyword">else</span> task
dataset = load_dataset(<span class="hljs-string">"glue"</span>, actual_task)
metric = load_metric(<span class="hljs-string">'glue'</span>, actual_task)
</code></pre>
<p>è¿™ä¸ª<code>datasets</code>å¯¹è±¡æœ¬èº«æ˜¯ä¸€ç§<a href="https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasetdict" target="_blank"><code>DatasetDict</code></a>æ•°æ®ç»“æ„. å¯¹äºè®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†ï¼Œåªéœ€è¦ä½¿ç”¨å¯¹åº”çš„keyï¼ˆtrainï¼Œvalidationï¼Œtestï¼‰å³å¯å¾—åˆ°ç›¸åº”çš„æ•°æ®ã€‚</p>
<pre><code class="lang-python">dataset
</code></pre>
<pre><code>DatasetDict({
    train: Dataset({
        features: ['sentence', 'label', 'idx'],
        num_rows: 8551
    })
    validation: Dataset({
        features: ['sentence', 'label', 'idx'],
        num_rows: 1043
    })
    test: Dataset({
        features: ['sentence', 'label', 'idx'],
        num_rows: 1063
    })
})
</code></pre><p>ç»™å®šä¸€ä¸ªæ•°æ®åˆ‡åˆ†çš„keyï¼ˆtrainã€validationæˆ–è€…testï¼‰å’Œä¸‹æ ‡å³å¯æŸ¥çœ‹æ•°æ®ã€‚</p>
<pre><code class="lang-python">dataset[<span class="hljs-string">"train"</span>][<span class="hljs-number">0</span>]
</code></pre>
<pre><code>{'idx': 0,
 'label': 1,
 'sentence': "Our friends won't buy this analysis, let alone the next one we propose."}
</code></pre><p>ä¸ºäº†èƒ½å¤Ÿè¿›ä¸€æ­¥ç†è§£æ•°æ®é•¿ä»€ä¹ˆæ ·å­ï¼Œä¸‹é¢çš„å‡½æ•°å°†ä»æ•°æ®é›†é‡Œéšæœºé€‰æ‹©å‡ ä¸ªä¾‹å­è¿›è¡Œå±•ç¤ºã€‚</p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> datasets
<span class="hljs-keyword">import</span> random
<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">from</span> IPython.display <span class="hljs-keyword">import</span> display, HTML

<span class="hljs-keyword">def</span> <span class="hljs-title function_">show_random_elements</span>(<span class="hljs-params">dataset, num_examples=<span class="hljs-number">10</span></span>):
    <span class="hljs-keyword">assert</span> num_examples &lt;= <span class="hljs-built_in">len</span>(dataset), <span class="hljs-string">"Can't pick more elements than there are in the dataset."</span>
    picks = []
    <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_examples):
        pick = random.randint(<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(dataset)-<span class="hljs-number">1</span>)
        <span class="hljs-keyword">while</span> pick <span class="hljs-keyword">in</span> picks:
            pick = random.randint(<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(dataset)-<span class="hljs-number">1</span>)
        picks.append(pick)

    df = pd.DataFrame(dataset[picks])
    <span class="hljs-keyword">for</span> column, typ <span class="hljs-keyword">in</span> dataset.features.items():
        <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(typ, datasets.ClassLabel):
            df[column] = df[column].transform(<span class="hljs-keyword">lambda</span> i: typ.names[i])
    display(HTML(df.to_html()))
</code></pre>
<pre><code class="lang-python">show_random_elements(dataset[<span class="hljs-string">"train"</span>])
</code></pre>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sentence</th>
      <th>label</th>
      <th>idx</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>The more I talk to Joe, the less about linguistics I am inclined to think Sally has taught him to appreciate.</td>
      <td>acceptable</td>
      <td>196</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Have in our class the kids arrived safely?</td>
      <td>unacceptable</td>
      <td>3748</td>
    </tr>
    <tr>
      <th>2</th>
      <td>I gave Mary a book.</td>
      <td>acceptable</td>
      <td>5302</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Every student, who attended the party, had a good time.</td>
      <td>unacceptable</td>
      <td>4944</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Bill pounded the metal fiat.</td>
      <td>acceptable</td>
      <td>2178</td>
    </tr>
    <tr>
      <th>5</th>
      <td>It bit me on the leg.</td>
      <td>acceptable</td>
      <td>5908</td>
    </tr>
    <tr>
      <th>6</th>
      <td>The boys were made a good mother by Aunt Mary.</td>
      <td>unacceptable</td>
      <td>736</td>
    </tr>
    <tr>
      <th>7</th>
      <td>More of a man is here.</td>
      <td>unacceptable</td>
      <td>5403</td>
    </tr>
    <tr>
      <th>8</th>
      <td>My mother baked me a birthday cake.</td>
      <td>acceptable</td>
      <td>3761</td>
    </tr>
    <tr>
      <th>9</th>
      <td>Gregory appears to have wanted to be loyal to the company.</td>
      <td>acceptable</td>
      <td>4334</td>
    </tr>
  </tbody>
</table>


<p>è¯„ä¼°meticæ˜¯<a href="https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Metric" target="_blank"><code>datasets.Metric</code></a>çš„ä¸€ä¸ªå®ä¾‹:</p>
<pre><code class="lang-python">metric
</code></pre>
<pre><code>Metric(name: "glue", features: {'predictions': Value(dtype='int64', id=None), 'references': Value(dtype='int64', id=None)}, usage: """
Compute GLUE evaluation metric associated to each GLUE dataset.
Args:
    predictions: list of predictions to score.
        Each translation should be tokenized into a list of tokens.
    references: list of lists of references for each translation.
        Each reference should be tokenized into a list of tokens.
Returns: depending on the GLUE subset, one or several of:
    "accuracy": Accuracy
    "f1": F1 score
    "pearson": Pearson Correlation
    "spearmanr": Spearman Correlation
    "matthews_correlation": Matthew Correlation
Examples:

    &gt;&gt;&gt; glue_metric = datasets.load_metric('glue', 'sst2')  # 'sst2' or any of ["mnli", "mnli_mismatched", "mnli_matched", "qnli", "rte", "wnli", "hans"]
    &gt;&gt;&gt; references = [0, 1]
    &gt;&gt;&gt; predictions = [0, 1]
    &gt;&gt;&gt; results = glue_metric.compute(predictions=predictions, references=references)
    &gt;&gt;&gt; print(results)
    {'accuracy': 1.0}

    &gt;&gt;&gt; glue_metric = datasets.load_metric('glue', 'mrpc')  # 'mrpc' or 'qqp'
    &gt;&gt;&gt; references = [0, 1]
    &gt;&gt;&gt; predictions = [0, 1]
    &gt;&gt;&gt; results = glue_metric.compute(predictions=predictions, references=references)
    &gt;&gt;&gt; print(results)
    {'accuracy': 1.0, 'f1': 1.0}

    &gt;&gt;&gt; glue_metric = datasets.load_metric('glue', 'stsb')
    &gt;&gt;&gt; references = [0., 1., 2., 3., 4., 5.]
    &gt;&gt;&gt; predictions = [0., 1., 2., 3., 4., 5.]
    &gt;&gt;&gt; results = glue_metric.compute(predictions=predictions, references=references)
    &gt;&gt;&gt; print({"pearson": round(results["pearson"], 2), "spearmanr": round(results["spearmanr"], 2)})
    {'pearson': 1.0, 'spearmanr': 1.0}

    &gt;&gt;&gt; glue_metric = datasets.load_metric('glue', 'cola')
    &gt;&gt;&gt; references = [0, 1]
    &gt;&gt;&gt; predictions = [0, 1]
    &gt;&gt;&gt; results = glue_metric.compute(predictions=predictions, references=references)
    &gt;&gt;&gt; print(results)
    {'matthews_correlation': 1.0}
""", stored examples: 0)
</code></pre><p>ç›´æ¥è°ƒç”¨metricçš„<code>compute</code>æ–¹æ³•ï¼Œä¼ å…¥<code>labels</code>å’Œ<code>predictions</code>å³å¯å¾—åˆ°metricçš„å€¼ï¼š</p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

fake_preds = np.random.randint(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, size=(<span class="hljs-number">64</span>,))
fake_labels = np.random.randint(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, size=(<span class="hljs-number">64</span>,))
metric.compute(predictions=fake_preds, references=fake_labels)
</code></pre>
<pre><code>{'matthews_correlation': 0.1513518081969605}
</code></pre><p>æ¯ä¸€ä¸ªæ–‡æœ¬åˆ†ç±»ä»»åŠ¡æ‰€å¯¹åº”çš„meticæœ‰æ‰€ä¸åŒï¼Œå…·ä½“å¦‚ä¸‹:</p>
<ul>
<li>for CoLA: <a href="https://en.wikipedia.org/wiki/Matthews_correlation_coefficient" target="_blank">Matthews Correlation Coefficient</a></li>
<li>for MNLI (matched or mismatched): Accuracy</li>
<li>for MRPC: Accuracy and <a href="https://en.wikipedia.org/wiki/F1_score" target="_blank">F1 score</a></li>
<li>for QNLI: Accuracy</li>
<li>for QQP: Accuracy and <a href="https://en.wikipedia.org/wiki/F1_score" target="_blank">F1 score</a></li>
<li>for RTE: Accuracy</li>
<li>for SST-2: Accuracy</li>
<li>for STS-B: <a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient" target="_blank">Pearson Correlation Coefficient</a> and <a href="https://en.wikipedia.org/wiki/Spearman%27s_rank_correlation_coefficient" target="_blank">Spearman's_Rank_Correlation_Coefficient</a></li>
<li>for WNLI: Accuracy</li>
</ul>
<p>æ‰€ä»¥ä¸€å®šè¦å°†metricå’Œä»»åŠ¡å¯¹é½</p>
<h2 id="æ•°æ®é¢„å¤„ç†">æ•°æ®é¢„å¤„ç†</h2>
<p>åœ¨å°†æ•°æ®å–‚å…¥æ¨¡å‹ä¹‹å‰ï¼Œæˆ‘ä»¬éœ€è¦å¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†ã€‚é¢„å¤„ç†çš„å·¥å…·å«<code>Tokenizer</code>ã€‚<code>Tokenizer</code>é¦–å…ˆå¯¹è¾“å…¥è¿›è¡Œtokenizeï¼Œç„¶åå°†tokensè½¬åŒ–ä¸ºé¢„æ¨¡å‹ä¸­éœ€è¦å¯¹åº”çš„token IDï¼Œå†è½¬åŒ–ä¸ºæ¨¡å‹éœ€è¦çš„è¾“å…¥æ ¼å¼ã€‚</p>
<p>ä¸ºäº†è¾¾åˆ°æ•°æ®é¢„å¤„ç†çš„ç›®çš„ï¼Œæˆ‘ä»¬ä½¿ç”¨<code>AutoTokenizer.from_pretrained</code>æ–¹æ³•å®ä¾‹åŒ–æˆ‘ä»¬çš„tokenizerï¼Œè¿™æ ·å¯ä»¥ç¡®ä¿ï¼š</p>
<ul>
<li>æˆ‘ä»¬å¾—åˆ°ä¸€ä¸ªä¸é¢„è®­ç»ƒæ¨¡å‹ä¸€ä¸€å¯¹åº”çš„tokenizerã€‚</li>
<li>ä½¿ç”¨æŒ‡å®šçš„æ¨¡å‹checkpointå¯¹åº”çš„tokenizerçš„æ—¶å€™ï¼Œæˆ‘ä»¬ä¹Ÿä¸‹è½½äº†æ¨¡å‹éœ€è¦çš„è¯è¡¨åº“vocabularyï¼Œå‡†ç¡®æ¥è¯´æ˜¯tokens vocabularyã€‚</li>
</ul>
<p>è¿™ä¸ªè¢«ä¸‹è½½çš„tokens vocabularyä¼šè¢«ç¼“å­˜èµ·æ¥ï¼Œä»è€Œå†æ¬¡ä½¿ç”¨çš„æ—¶å€™ä¸ä¼šé‡æ–°ä¸‹è½½ã€‚</p>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=<span class="hljs-literal">True</span>)
</code></pre>
<p>æ³¨æ„ï¼š<code>use_fast=True</code>è¦æ±‚tokenizerå¿…é¡»æ˜¯transformers.PreTrainedTokenizerFastç±»å‹ï¼Œå› ä¸ºæˆ‘ä»¬åœ¨é¢„å¤„ç†çš„æ—¶å€™éœ€è¦ç”¨åˆ°fast tokenizerçš„ä¸€äº›ç‰¹æ®Šç‰¹æ€§ï¼ˆæ¯”å¦‚å¤šçº¿ç¨‹å¿«é€Ÿtokenizerï¼‰ã€‚å¦‚æœå¯¹åº”çš„æ¨¡å‹æ²¡æœ‰fast tokenizerï¼Œå»æ‰è¿™ä¸ªé€‰é¡¹å³å¯ã€‚</p>
<p>å‡ ä¹æ‰€æœ‰æ¨¡å‹å¯¹åº”çš„tokenizeréƒ½æœ‰å¯¹åº”çš„fast tokenizerã€‚æˆ‘ä»¬å¯ä»¥åœ¨<a href="https://huggingface.co/transformers/index.html#bigtable" target="_blank">æ¨¡å‹tokenizerå¯¹åº”è¡¨</a>é‡ŒæŸ¥çœ‹æ‰€æœ‰é¢„è®­ç»ƒæ¨¡å‹å¯¹åº”çš„tokenizeræ‰€æ‹¥æœ‰çš„ç‰¹ç‚¹ã€‚</p>
<p>tokenizeræ—¢å¯ä»¥å¯¹å•ä¸ªæ–‡æœ¬è¿›è¡Œé¢„å¤„ç†ï¼Œä¹Ÿå¯ä»¥å¯¹ä¸€å¯¹æ–‡æœ¬è¿›è¡Œé¢„å¤„ç†ï¼Œtokenizeré¢„å¤„ç†åå¾—åˆ°çš„æ•°æ®æ»¡è¶³é¢„è®­ç»ƒæ¨¡å‹è¾“å…¥æ ¼å¼</p>
<pre><code class="lang-python">tokenizer(<span class="hljs-string">"Hello, this one sentence!"</span>, <span class="hljs-string">"And this sentence goes with it."</span>)
</code></pre>
<pre><code>{'input_ids': [101, 7592, 1010, 2023, 2028, 6251, 999, 102, 1998, 2023, 6251, 3632, 2007, 2009, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}
</code></pre><p>å–å†³äºæˆ‘ä»¬é€‰æ‹©çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œæˆ‘ä»¬å°†ä¼šçœ‹åˆ°tokenizeræœ‰ä¸åŒçš„è¿”å›ï¼Œtokenizerå’Œé¢„è®­ç»ƒæ¨¡å‹æ˜¯ä¸€ä¸€å¯¹åº”çš„ï¼Œæ›´å¤šä¿¡æ¯å¯ä»¥åœ¨<a href="https://huggingface.co/transformers/preprocessing.html" target="_blank">è¿™é‡Œ</a>è¿›è¡Œå­¦ä¹ ã€‚</p>
<p>ä¸ºäº†é¢„å¤„ç†æˆ‘ä»¬çš„æ•°æ®ï¼Œæˆ‘ä»¬éœ€è¦çŸ¥é“ä¸åŒæ•°æ®å’Œå¯¹åº”çš„æ•°æ®æ ¼å¼ï¼Œå› æ­¤æˆ‘ä»¬å®šä¹‰ä¸‹é¢è¿™ä¸ªdictã€‚</p>
<pre><code class="lang-python">task_to_keys = {
    <span class="hljs-string">"cola"</span>: (<span class="hljs-string">"sentence"</span>, <span class="hljs-literal">None</span>),
    <span class="hljs-string">"mnli"</span>: (<span class="hljs-string">"premise"</span>, <span class="hljs-string">"hypothesis"</span>),
    <span class="hljs-string">"mnli-mm"</span>: (<span class="hljs-string">"premise"</span>, <span class="hljs-string">"hypothesis"</span>),
    <span class="hljs-string">"mrpc"</span>: (<span class="hljs-string">"sentence1"</span>, <span class="hljs-string">"sentence2"</span>),
    <span class="hljs-string">"qnli"</span>: (<span class="hljs-string">"question"</span>, <span class="hljs-string">"sentence"</span>),
    <span class="hljs-string">"qqp"</span>: (<span class="hljs-string">"question1"</span>, <span class="hljs-string">"question2"</span>),
    <span class="hljs-string">"rte"</span>: (<span class="hljs-string">"sentence1"</span>, <span class="hljs-string">"sentence2"</span>),
    <span class="hljs-string">"sst2"</span>: (<span class="hljs-string">"sentence"</span>, <span class="hljs-literal">None</span>),
    <span class="hljs-string">"stsb"</span>: (<span class="hljs-string">"sentence1"</span>, <span class="hljs-string">"sentence2"</span>),
    <span class="hljs-string">"wnli"</span>: (<span class="hljs-string">"sentence1"</span>, <span class="hljs-string">"sentence2"</span>),
}
</code></pre>
<p>å¯¹æ•°æ®æ ¼å¼è¿›è¡Œæ£€æŸ¥:</p>
<pre><code class="lang-python">sentence1_key, sentence2_key = task_to_keys[task]
<span class="hljs-keyword">if</span> sentence2_key <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f"Sentence: <span class="hljs-subst">{dataset[<span class="hljs-string">'train'</span>][<span class="hljs-number">0</span>][sentence1_key]}</span>"</span>)
<span class="hljs-keyword">else</span>:
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f"Sentence 1: <span class="hljs-subst">{dataset[<span class="hljs-string">'train'</span>][<span class="hljs-number">0</span>][sentence1_key]}</span>"</span>)
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f"Sentence 2: <span class="hljs-subst">{dataset[<span class="hljs-string">'train'</span>][<span class="hljs-number">0</span>][sentence2_key]}</span>"</span>)
</code></pre>
<pre><code>Sentence: Our friends won't buy this analysis, let alone the next one we propose.
</code></pre><p>éšåå°†é¢„å¤„ç†çš„ä»£ç æ”¾åˆ°ä¸€ä¸ªå‡½æ•°ä¸­ï¼š</p>
<pre><code class="lang-python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">preprocess_function</span>(<span class="hljs-params">examples</span>):
    <span class="hljs-keyword">if</span> sentence2_key <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:
        <span class="hljs-keyword">return</span> tokenizer(examples[sentence1_key], truncation=<span class="hljs-literal">True</span>)
    <span class="hljs-keyword">return</span> tokenizer(examples[sentence1_key], examples[sentence2_key], truncation=<span class="hljs-literal">True</span>)
</code></pre>
<p>é¢„å¤„ç†å‡½æ•°å¯ä»¥å¤„ç†å•ä¸ªæ ·æœ¬ï¼Œä¹Ÿå¯ä»¥å¯¹å¤šä¸ªæ ·æœ¬è¿›è¡Œå¤„ç†ã€‚å¦‚æœè¾“å…¥æ˜¯å¤šä¸ªæ ·æœ¬ï¼Œé‚£ä¹ˆè¿”å›çš„æ˜¯ä¸€ä¸ªlistï¼š</p>
<pre><code class="lang-python">preprocess_function(dataset[<span class="hljs-string">'train'</span>][:<span class="hljs-number">5</span>])
</code></pre>
<pre><code>{'input_ids': [[101, 2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012, 102], [101, 2028, 2062, 18404, 2236, 3989, 1998, 1045, 1005, 1049, 3228, 2039, 1012, 102], [101, 2028, 2062, 18404, 2236, 3989, 2030, 1045, 1005, 1049, 3228, 2039, 1012, 102], [101, 1996, 2062, 2057, 2817, 16025, 1010, 1996, 13675, 16103, 2121, 2027, 2131, 1012, 102], [101, 2154, 2011, 2154, 1996, 8866, 2024, 2893, 14163, 8024, 3771, 1012, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}
</code></pre><p>æ¥ä¸‹æ¥å¯¹æ•°æ®é›†datasetsé‡Œé¢çš„æ‰€æœ‰æ ·æœ¬è¿›è¡Œé¢„å¤„ç†ï¼Œå¤„ç†çš„æ–¹å¼æ˜¯ä½¿ç”¨mapå‡½æ•°ï¼Œå°†é¢„å¤„ç†å‡½æ•°prepare_train_featuresåº”ç”¨åˆ°ï¼ˆmap)æ‰€æœ‰æ ·æœ¬ä¸Šã€‚</p>
<pre><code class="lang-python">encoded_dataset = dataset.<span class="hljs-built_in">map</span>(preprocess_function, batched=<span class="hljs-literal">True</span>)
</code></pre>
<p>æ›´å¥½çš„æ˜¯ï¼Œè¿”å›çš„ç»“æœä¼šè‡ªåŠ¨è¢«ç¼“å­˜ï¼Œé¿å…ä¸‹æ¬¡å¤„ç†çš„æ—¶å€™é‡æ–°è®¡ç®—ï¼ˆä½†æ˜¯ä¹Ÿè¦æ³¨æ„ï¼Œå¦‚æœè¾“å…¥æœ‰æ”¹åŠ¨ï¼Œå¯èƒ½ä¼šè¢«ç¼“å­˜å½±å“ï¼ï¼‰ã€‚datasetsåº“å‡½æ•°ä¼šå¯¹è¾“å…¥çš„å‚æ•°è¿›è¡Œæ£€æµ‹ï¼Œåˆ¤æ–­æ˜¯å¦æœ‰å˜åŒ–ï¼Œå¦‚æœæ²¡æœ‰å˜åŒ–å°±ä½¿ç”¨ç¼“å­˜æ•°æ®ï¼Œå¦‚æœæœ‰å˜åŒ–å°±é‡æ–°å¤„ç†ã€‚ä½†å¦‚æœè¾“å…¥å‚æ•°ä¸å˜ï¼Œæƒ³æ”¹å˜è¾“å…¥çš„æ—¶å€™ï¼Œæœ€å¥½æ¸…ç†è°ƒè¿™ä¸ªç¼“å­˜ã€‚æ¸…ç†çš„æ–¹å¼æ˜¯ä½¿ç”¨<code>load_from_cache_file=False</code>å‚æ•°ã€‚å¦å¤–ï¼Œä¸Šé¢ä½¿ç”¨åˆ°çš„<code>batched=True</code>è¿™ä¸ªå‚æ•°æ˜¯tokenizerçš„ç‰¹ç‚¹ï¼Œä»¥ä¸ºè¿™ä¼šä½¿ç”¨å¤šçº¿ç¨‹åŒæ—¶å¹¶è¡Œå¯¹è¾“å…¥è¿›è¡Œå¤„ç†ã€‚</p>
<h2 id="å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹">å¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹</h2>
<p>æ—¢ç„¶æ•°æ®å·²ç»å‡†å¤‡å¥½äº†ï¼Œç°åœ¨æˆ‘ä»¬éœ€è¦ä¸‹è½½å¹¶åŠ è½½æˆ‘ä»¬çš„é¢„è®­ç»ƒæ¨¡å‹ï¼Œç„¶åå¾®è°ƒé¢„è®­ç»ƒæ¨¡å‹ã€‚æ—¢ç„¶æˆ‘ä»¬æ˜¯åšseq2seqä»»åŠ¡ï¼Œé‚£ä¹ˆæˆ‘ä»¬éœ€è¦ä¸€ä¸ªèƒ½è§£å†³è¿™ä¸ªä»»åŠ¡çš„æ¨¡å‹ç±»ã€‚æˆ‘ä»¬ä½¿ç”¨<code>AutoModelForSequenceClassification</code> è¿™ä¸ªç±»ã€‚å’Œtokenizerç›¸ä¼¼ï¼Œ<code>from_pretrained</code>æ–¹æ³•åŒæ ·å¯ä»¥å¸®åŠ©æˆ‘ä»¬ä¸‹è½½å¹¶åŠ è½½æ¨¡å‹ï¼ŒåŒæ—¶ä¹Ÿä¼šå¯¹æ¨¡å‹è¿›è¡Œç¼“å­˜ï¼Œå°±ä¸ä¼šé‡å¤ä¸‹è½½æ¨¡å‹å•¦ã€‚</p>
<p>éœ€è¦æ³¨æ„çš„æ˜¯ï¼šSTS-Bæ˜¯ä¸€ä¸ªå›å½’é—®é¢˜ï¼ŒMNLIæ˜¯ä¸€ä¸ª3åˆ†ç±»é—®é¢˜ï¼š</p>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForSequenceClassification, TrainingArguments, Trainer

num_labels = <span class="hljs-number">3</span> <span class="hljs-keyword">if</span> task.startswith(<span class="hljs-string">"mnli"</span>) <span class="hljs-keyword">else</span> <span class="hljs-number">1</span> <span class="hljs-keyword">if</span> task==<span class="hljs-string">"stsb"</span> <span class="hljs-keyword">else</span> <span class="hljs-number">2</span>
model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)
</code></pre>
<pre><code>Downloading:   0%|          | 0.00/268M [00:00&lt;?, ?B/s]


Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight']
- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
</code></pre><p>ç”±äºæˆ‘ä»¬å¾®è°ƒçš„ä»»åŠ¡æ˜¯æ–‡æœ¬åˆ†ç±»ä»»åŠ¡ï¼Œè€Œæˆ‘ä»¬åŠ è½½çš„æ˜¯é¢„è®­ç»ƒçš„è¯­è¨€æ¨¡å‹ï¼Œæ‰€ä»¥ä¼šæç¤ºæˆ‘ä»¬åŠ è½½æ¨¡å‹çš„æ—¶å€™æ‰”æ‰äº†ä¸€äº›ä¸åŒ¹é…çš„ç¥ç»ç½‘ç»œå‚æ•°ï¼ˆæ¯”å¦‚ï¼šé¢„è®­ç»ƒè¯­è¨€æ¨¡å‹çš„ç¥ç»ç½‘ç»œheadè¢«æ‰”æ‰äº†ï¼ŒåŒæ—¶éšæœºåˆå§‹åŒ–äº†æ–‡æœ¬åˆ†ç±»çš„ç¥ç»ç½‘ç»œheadï¼‰ã€‚</p>
<p>ä¸ºäº†èƒ½å¤Ÿå¾—åˆ°ä¸€ä¸ª<code>Trainer</code>è®­ç»ƒå·¥å…·ï¼Œæˆ‘ä»¬è¿˜éœ€è¦3ä¸ªè¦ç´ ï¼Œå…¶ä¸­æœ€é‡è¦çš„æ˜¯è®­ç»ƒçš„è®¾å®š/å‚æ•° <a href="https://huggingface.co/transformers/main_classes/trainer.html#transformers.TrainingArguments" target="_blank"><code>TrainingArguments</code></a>ã€‚è¿™ä¸ªè®­ç»ƒè®¾å®šåŒ…å«äº†èƒ½å¤Ÿå®šä¹‰è®­ç»ƒè¿‡ç¨‹çš„æ‰€æœ‰å±æ€§ã€‚</p>
<pre><code class="lang-python">metric_name = <span class="hljs-string">"pearson"</span> <span class="hljs-keyword">if</span> task == <span class="hljs-string">"stsb"</span> <span class="hljs-keyword">else</span> <span class="hljs-string">"matthews_correlation"</span> <span class="hljs-keyword">if</span> task == <span class="hljs-string">"cola"</span> <span class="hljs-keyword">else</span> <span class="hljs-string">"accuracy"</span>

args = TrainingArguments(
    <span class="hljs-string">"test-glue"</span>,
    evaluation_strategy = <span class="hljs-string">"epoch"</span>,
    save_strategy = <span class="hljs-string">"epoch"</span>,
    learning_rate=<span class="hljs-number">2e-5</span>,
    per_device_train_batch_size=batch_size,
    per_device_eval_batch_size=batch_size,
    num_train_epochs=<span class="hljs-number">5</span>,
    weight_decay=<span class="hljs-number">0.01</span>,
    load_best_model_at_end=<span class="hljs-literal">True</span>,
    metric_for_best_model=metric_name,
)
</code></pre>
<p>ä¸Šé¢evaluation_strategy = "epoch"å‚æ•°å‘Šè¯‰è®­ç»ƒä»£ç ï¼šæˆ‘ä»¬æ¯ä¸ªepcohä¼šåšä¸€æ¬¡éªŒè¯è¯„ä¼°ã€‚</p>
<p>ä¸Šé¢batch_sizeåœ¨è¿™ä¸ªnotebookä¹‹å‰å®šä¹‰å¥½äº†ã€‚</p>
<p>æœ€åï¼Œç”±äºä¸åŒçš„ä»»åŠ¡éœ€è¦ä¸åŒçš„è¯„æµ‹æŒ‡æ ‡ï¼Œæˆ‘ä»¬å®šä¸€ä¸ªå‡½æ•°æ¥æ ¹æ®ä»»åŠ¡åå­—å¾—åˆ°è¯„ä»·æ–¹æ³•:</p>
<pre><code class="lang-python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">compute_metrics</span>(<span class="hljs-params">eval_pred</span>):
    predictions, labels = eval_pred
    <span class="hljs-keyword">if</span> task != <span class="hljs-string">"stsb"</span>:
        predictions = np.argmax(predictions, axis=<span class="hljs-number">1</span>)
    <span class="hljs-keyword">else</span>:
        predictions = predictions[:, <span class="hljs-number">0</span>]
    <span class="hljs-keyword">return</span> metric.compute(predictions=predictions, references=labels)
</code></pre>
<p>å…¨éƒ¨ä¼ ç»™ <code>Trainer</code>:</p>
<pre><code class="lang-python">validation_key = <span class="hljs-string">"validation_mismatched"</span> <span class="hljs-keyword">if</span> task == <span class="hljs-string">"mnli-mm"</span> <span class="hljs-keyword">else</span> <span class="hljs-string">"validation_matched"</span> <span class="hljs-keyword">if</span> task == <span class="hljs-string">"mnli"</span> <span class="hljs-keyword">else</span> <span class="hljs-string">"validation"</span>
trainer = Trainer(
    model,
    args,
    train_dataset=encoded_dataset[<span class="hljs-string">"train"</span>],
    eval_dataset=encoded_dataset[validation_key],
    tokenizer=tokenizer,
    compute_metrics=compute_metrics
)
</code></pre>
<p>å¼€å§‹è®­ç»ƒ:</p>
<pre><code class="lang-python">trainer.train()
</code></pre>
<pre><code>The following columns in the training set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: idx, sentence.
***** Running training *****
  Num examples = 8551
  Num Epochs = 5
  Instantaneous batch size per device = 16
  Total train batch size (w. parallel, distributed &amp; accumulation) = 16
  Gradient Accumulation steps = 1
  Total optimization steps = 2675




&lt;div&gt;

  &lt;progress value='2675' max='2675' style='width:300px; height:20px; vertical-align: middle;'&gt;&lt;/progress&gt;
  [2675/2675 02:49, Epoch 5/5]
&lt;/div&gt;
&lt;table border="1" class="dataframe"&gt;
</code></pre><p>  <thead>
    <tr style="text-align: left;">
      <th>Epoch</th>
      <th>Training Loss</th>
      <th>Validation Loss</th>
      <th>Matthews Correlation</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>0.525400</td>
      <td>0.520955</td>
      <td>0.409248</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0.351600</td>
      <td>0.570341</td>
      <td>0.477499</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0.236100</td>
      <td>0.622785</td>
      <td>0.499872</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0.166300</td>
      <td>0.806475</td>
      <td>0.491623</td>
    </tr>
    <tr>
      <td>5</td>
      <td>0.125700</td>
      <td>0.882225</td>
      <td>0.513900</td>
    </tr>
  </tbody>
&lt;/table&gt;</p><p></p>
<pre><code>The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: idx, sentence.
***** Running Evaluation *****
  Num examples = 1043
  Batch size = 16
Saving model checkpoint to test-glue/checkpoint-535
Configuration saved in test-glue/checkpoint-535/config.json
Model weights saved in test-glue/checkpoint-535/pytorch_model.bin
tokenizer config file saved in test-glue/checkpoint-535/tokenizer_config.json
Special tokens file saved in test-glue/checkpoint-535/special_tokens_map.json
The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: idx, sentence.
***** Running Evaluation *****
  Num examples = 1043
  Batch size = 16
Saving model checkpoint to test-glue/checkpoint-1070
Configuration saved in test-glue/checkpoint-1070/config.json
Model weights saved in test-glue/checkpoint-1070/pytorch_model.bin
tokenizer config file saved in test-glue/checkpoint-1070/tokenizer_config.json
Special tokens file saved in test-glue/checkpoint-1070/special_tokens_map.json
The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: idx, sentence.
***** Running Evaluation *****
  Num examples = 1043
  Batch size = 16
Saving model checkpoint to test-glue/checkpoint-1605
Configuration saved in test-glue/checkpoint-1605/config.json
Model weights saved in test-glue/checkpoint-1605/pytorch_model.bin
tokenizer config file saved in test-glue/checkpoint-1605/tokenizer_config.json
Special tokens file saved in test-glue/checkpoint-1605/special_tokens_map.json
The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: idx, sentence.
***** Running Evaluation *****
  Num examples = 1043
  Batch size = 16
Saving model checkpoint to test-glue/checkpoint-2140
Configuration saved in test-glue/checkpoint-2140/config.json
Model weights saved in test-glue/checkpoint-2140/pytorch_model.bin
tokenizer config file saved in test-glue/checkpoint-2140/tokenizer_config.json
Special tokens file saved in test-glue/checkpoint-2140/special_tokens_map.json
The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: idx, sentence.
***** Running Evaluation *****
  Num examples = 1043
  Batch size = 16
Saving model checkpoint to test-glue/checkpoint-2675
Configuration saved in test-glue/checkpoint-2675/config.json
Model weights saved in test-glue/checkpoint-2675/pytorch_model.bin
tokenizer config file saved in test-glue/checkpoint-2675/tokenizer_config.json
Special tokens file saved in test-glue/checkpoint-2675/special_tokens_map.json


Training completed. Do not forget to share your model on huggingface.co/models =)


Loading best model from test-glue/checkpoint-2675 (score: 0.5138995234247261).





TrainOutput(global_step=2675, training_loss=0.27181456521292713, metrics={'train_runtime': 169.649, 'train_samples_per_second': 252.02, 'train_steps_per_second': 15.768, 'total_flos': 229537542078168.0, 'train_loss': 0.27181456521292713, 'epoch': 5.0})
</code></pre><p>è®­ç»ƒå®Œæˆåè¿›è¡Œè¯„ä¼°:</p>
<pre><code class="lang-python">trainer.evaluate()
</code></pre>
<pre><code>The following columns in the evaluation set  don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: idx, sentence.
***** Running Evaluation *****
  Num examples = 1043
  Batch size = 16
</code></pre><div>

  <progress value="66" max="66" style="width:300px; height:20px; vertical-align: middle;"></progress>
  [66/66 00:00]
</div>






<pre><code>{'epoch': 5.0,
 'eval_loss': 0.8822253346443176,
 'eval_matthews_correlation': 0.5138995234247261,
 'eval_runtime': 0.9319,
 'eval_samples_per_second': 1119.255,
 'eval_steps_per_second': 70.825}
</code></pre><p>To see how your model fared you can compare it to the <a href="https://gluebenchmark.com/leaderboard" target="_blank">GLUE Benchmark leaderboard</a>.</p>
<h2 id="è¶…å‚æ•°æœç´¢">è¶…å‚æ•°æœç´¢</h2>
<p><code>Trainer</code>åŒæ ·æ”¯æŒè¶…å‚æœç´¢ï¼Œä½¿ç”¨<a href="https://optuna.org/" target="_blank">optuna</a> or <a href="https://docs.ray.io/en/latest/tune/" target="_blank">Ray Tune</a>ä»£ç åº“ã€‚</p>
<p>åæ³¨é‡Šä¸‹é¢ä¸¤è¡Œå®‰è£…ä¾èµ–ï¼š</p>
<pre><code class="lang-python">! pip install optuna
! pip install ray[tune]
</code></pre>
<p>è¶…å‚æœç´¢æ—¶ï¼Œ<code>Trainer</code>å°†ä¼šè¿”å›å¤šä¸ªè®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œæ‰€ä»¥éœ€è¦ä¼ å…¥ä¸€ä¸ªå®šä¹‰å¥½çš„æ¨¡å‹ä»è€Œè®©<code>Trainer</code>å¯ä»¥ä¸æ–­é‡æ–°åˆå§‹åŒ–è¯¥ä¼ å…¥çš„æ¨¡å‹ï¼š</p>
<pre><code class="lang-python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">model_init</span>():
    <span class="hljs-keyword">return</span> AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)
</code></pre>
<p>å’Œä¹‹å‰è°ƒç”¨ <code>Trainer</code>ç±»ä¼¼:</p>
<pre><code class="lang-python">trainer = Trainer(
    model_init=model_init,
    args=args,
    train_dataset=encoded_dataset[<span class="hljs-string">"train"</span>],
    eval_dataset=encoded_dataset[validation_key],
    tokenizer=tokenizer,
    compute_metrics=compute_metrics
)
</code></pre>
<pre><code>loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.d423bdf2f58dc8b77d5f5d18028d7ae4a72dcfd8f468e81fe979ada957a8c361
Model config DistilBertConfig {
  "activation": "gelu",
  "architectures": [
    "DistilBertForMaskedLM"
  ],
  "attention_dropout": 0.1,
  "dim": 768,
  "dropout": 0.1,
  "hidden_dim": 3072,
  "initializer_range": 0.02,
  "max_position_embeddings": 512,
  "model_type": "distilbert",
  "n_heads": 12,
  "n_layers": 6,
  "pad_token_id": 0,
  "qa_dropout": 0.1,
  "seq_classif_dropout": 0.2,
  "sinusoidal_pos_embds": false,
  "tie_weights_": true,
  "transformers_version": "4.9.1",
  "vocab_size": 30522
}

loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a
Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight']
- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
</code></pre><p>è°ƒç”¨æ–¹æ³•<code>hyperparameter_search</code>ã€‚æ³¨æ„ï¼Œè¿™ä¸ªè¿‡ç¨‹å¯èƒ½å¾ˆä¹…ï¼Œæˆ‘ä»¬å¯ä»¥å…ˆç”¨éƒ¨åˆ†æ•°æ®é›†è¿›è¡Œè¶…å‚æœç´¢ï¼Œå†è¿›è¡Œå…¨é‡è®­ç»ƒã€‚
æ¯”å¦‚ä½¿ç”¨1/10çš„æ•°æ®è¿›è¡Œæœç´¢ï¼š</p>
<pre><code class="lang-python">best_run = trainer.hyperparameter_search(n_trials=<span class="hljs-number">10</span>, direction=<span class="hljs-string">"maximize"</span>)
</code></pre>
<p><code>hyperparameter_search</code>ä¼šè¿”å›æ•ˆæœæœ€å¥½çš„æ¨¡å‹ç›¸å…³çš„å‚æ•°ï¼š</p>
<pre><code class="lang-python">best_run
</code></pre>
<p>å°†<code>Trainner</code>è®¾ç½®ä¸ºæœç´¢åˆ°çš„æœ€å¥½å‚æ•°ï¼Œè¿›è¡Œè®­ç»ƒï¼š</p>
<pre><code class="lang-python"><span class="hljs-keyword">for</span> n, v <span class="hljs-keyword">in</span> best_run.hyperparameters.items():
    <span class="hljs-built_in">setattr</span>(trainer.args, n, v)

trainer.train()
</code></pre>
<p>æœ€ååˆ«å¿˜äº†ï¼ŒæŸ¥çœ‹å¦‚ä½•ä¸Šä¼ æ¨¡å‹ ï¼Œä¸Šä¼ æ¨¡å‹åˆ°](<a href="https://huggingface.co/transformers/model_sharing.html" target="_blank">https://huggingface.co/transformers/model_sharing.html</a>) åˆ°<a href="https://huggingface.co/models" target="_blank">ğŸ¤— Model Hub</a>ã€‚éšåæ‚¨å°±å¯ä»¥åƒè¿™ä¸ªnotebookä¸€å¼€å§‹ä¸€æ ·ï¼Œç›´æ¥ç”¨æ¨¡å‹åå­—å°±èƒ½ä½¿ç”¨æ‚¨è‡ªå·±ä¸Šä¼ çš„æ¨¡å‹å•¦ã€‚</p>
<pre><code class="lang-python">

</code></pre>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="4.0-åŸºäºHuggingFace-Transformersçš„é¢„è®­ç»ƒæ¨¡å‹å¾®è°ƒ.html" class="navigation navigation-prev " aria-label="Previous page: 4.0-åŸºäºHuggingFace-Transformersçš„é¢„è®­ç»ƒæ¨¡å‹å¾®è°ƒ">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="4.2-åºåˆ—æ ‡æ³¨.html" class="navigation navigation-next " aria-label="Next page: 4.2-åºåˆ—æ ‡æ³¨">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"4.1-æ–‡æœ¬åˆ†ç±»","level":"4.3","depth":1,"next":{"title":"4.2-åºåˆ—æ ‡æ³¨","level":"4.4","depth":1,"path":"ç¯‡ç« 4-ä½¿ç”¨Transformersè§£å†³NLPä»»åŠ¡/4.2-åºåˆ—æ ‡æ³¨.md","ref":"./ç¯‡ç« 4-ä½¿ç”¨Transformersè§£å†³NLPä»»åŠ¡/4.2-åºåˆ—æ ‡æ³¨.md","articles":[]},"previous":{"title":"4.0-åŸºäºHuggingFace-Transformersçš„é¢„è®­ç»ƒæ¨¡å‹å¾®è°ƒ","level":"4.2","depth":1,"path":"ç¯‡ç« 4-ä½¿ç”¨Transformersè§£å†³NLPä»»åŠ¡/4.0-åŸºäºHuggingFace-Transformersçš„é¢„è®­ç»ƒæ¨¡å‹å¾®è°ƒ.md","ref":"./ç¯‡ç« 4-ä½¿ç”¨Transformersè§£å†³NLPä»»åŠ¡/4.0-åŸºäºHuggingFace-Transformersçš„é¢„è®­ç»ƒæ¨¡å‹å¾®è°ƒ.md","articles":[]},"dir":"ltr"},"config":{"gitbook":"*","theme":"default","variables":{},"plugins":["livereload"],"pluginsConfig":{"livereload":{},"highlight":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56},"embedFonts":false},"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"}},"file":{"path":"ç¯‡ç« 4-ä½¿ç”¨Transformersè§£å†³NLPä»»åŠ¡/4.1-æ–‡æœ¬åˆ†ç±».md","mtime":"2024-08-23T15:34:37.383Z","type":"markdown"},"gitbook":{"version":"5.1.4","time":"2024-08-23T15:50:04.957Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <noscript>
        <style>
            .honkit-cloak {
                display: block !important;
            }
        </style>
    </noscript>
    <script>
        // Restore sidebar state as critical path for prevent layout shift
        function __init__getSidebarState(defaultValue){
            var baseKey = "";
            var key = baseKey + ":sidebar";
            try {
                var value = localStorage[key];
                if (value === undefined) {
                    return defaultValue;
                }
                var parsed = JSON.parse(value);
                return parsed == null ? defaultValue : parsed;
            } catch (e) {
                return defaultValue;
            }
        }
        function __init__restoreLastSidebarState() {
            var isMobile = window.matchMedia("(max-width: 600px)").matches;
            if (isMobile) {
                // Init last state if not mobile
                return;
            }
            var sidebarState = __init__getSidebarState(true);
            var book = document.querySelector(".book");
            // Show sidebar if it enabled
            if (sidebarState && book) {
                book.classList.add("without-animation", "with-summary");
            }
        }

        try {
            __init__restoreLastSidebarState();
        } finally {
            var book = document.querySelector(".book");
            book.classList.remove("honkit-cloak");
        }
    </script>
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="../gitbook/gitbook-plugin-livereload/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

