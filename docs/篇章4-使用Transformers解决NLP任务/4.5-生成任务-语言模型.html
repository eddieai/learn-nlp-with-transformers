
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <title>4.5-ç”Ÿæˆä»»åŠ¡-è¯­è¨€æ¨¡å‹ Â· HonKit</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="HonKit 5.1.4">
        
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/@honkit/honkit-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=3, user-scalable=yes">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="4.6-ç”Ÿæˆä»»åŠ¡-æœºå™¨ç¿»è¯‘.html" />
    
    
    <link rel="prev" href="4.4-é—®ç­”ä»»åŠ¡-å¤šé€‰é—®ç­”.html" />
    

    </head>
    <body>
        
<div class="book honkit-cloak">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        <li class="header">ç¯‡ç« 1-å‰è¨€</li>
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" data-path="../ç¯‡ç« 1-å‰è¨€/1.0-æœ¬åœ°é˜…è¯»å’Œä»£ç è¿è¡Œç¯å¢ƒé…ç½®.html">
            
                <a href="../ç¯‡ç« 1-å‰è¨€/1.0-æœ¬åœ°é˜…è¯»å’Œä»£ç è¿è¡Œç¯å¢ƒé…ç½®.html">
            
                    
                    1.0-æœ¬åœ°é˜…è¯»å’Œä»£ç è¿è¡Œç¯å¢ƒé…ç½®
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="../ç¯‡ç« 1-å‰è¨€/1.1-Transformersåœ¨NLPä¸­çš„å…´èµ·.html">
            
                <a href="../ç¯‡ç« 1-å‰è¨€/1.1-Transformersåœ¨NLPä¸­çš„å…´èµ·.html">
            
                    
                    1.1-Transformersåœ¨NLPä¸­çš„å…´èµ·
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">ç¯‡ç« 2-Transformerç›¸å…³åŸç†</li>
        
        
    
        <li class="chapter " data-level="2.1" data-path="../ç¯‡ç« 2-Transformerç›¸å…³åŸç†/2.0-å‰è¨€.html">
            
                <a href="../ç¯‡ç« 2-Transformerç›¸å…³åŸç†/2.0-å‰è¨€.html">
            
                    
                    2.0-å‰è¨€
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.2" data-path="../ç¯‡ç« 2-Transformerç›¸å…³åŸç†/2.1-å›¾è§£attention.html">
            
                <a href="../ç¯‡ç« 2-Transformerç›¸å…³åŸç†/2.1-å›¾è§£attention.html">
            
                    
                    2.1-å›¾è§£attention
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.3" data-path="../ç¯‡ç« 2-Transformerç›¸å…³åŸç†/2.2-å›¾è§£transformer.html">
            
                <a href="../ç¯‡ç« 2-Transformerç›¸å…³åŸç†/2.2-å›¾è§£transformer.html">
            
                    
                    2.2-å›¾è§£transformer
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.4" data-path="../ç¯‡ç« 2-Transformerç›¸å…³åŸç†/2.2.1-Pytorchç¼–å†™Transformer.html">
            
                <a href="../ç¯‡ç« 2-Transformerç›¸å…³åŸç†/2.2.1-Pytorchç¼–å†™Transformer.html">
            
                    
                    2.2.1-Pytorchç¼–å†™Transformer
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.5" data-path="../ç¯‡ç« 2-Transformerç›¸å…³åŸç†/2.2.1-Pytorchç¼–å†™Transformer-é€‰è¯».md">
            
                <span>
            
                    
                    2.2.2-Pytorchç¼–å†™Transformer-é€‰è¯»
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.6" data-path="../ç¯‡ç« 2-Transformerç›¸å…³åŸç†/2.3-å›¾è§£BERT.html">
            
                <a href="../ç¯‡ç« 2-Transformerç›¸å…³åŸç†/2.3-å›¾è§£BERT.html">
            
                    
                    2.3-å›¾è§£BERT
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.7" data-path="../ç¯‡ç« 2-Transformerç›¸å…³åŸç†/2.4-å›¾è§£GPT.html">
            
                <a href="../ç¯‡ç« 2-Transformerç›¸å…³åŸç†/2.4-å›¾è§£GPT.html">
            
                    
                    2.4-å›¾è§£GPT
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="2.8" data-path="../ç¯‡ç« 2-Transformerç›¸å…³åŸç†/2.5-ç¯‡ç« å°æµ‹.html">
            
                <a href="../ç¯‡ç« 2-Transformerç›¸å…³åŸç†/2.5-ç¯‡ç« å°æµ‹.html">
            
                    
                    2.5-ç¯‡ç« å°æµ‹
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">ç¯‡ç« 3-ç¼–å†™ä¸€ä¸ªTransformeræ¨¡å‹ï¼šBERT</li>
        
        
    
        <li class="chapter " data-level="3.1" data-path="../ç¯‡ç« 3-ç¼–å†™ä¸€ä¸ªTransformeræ¨¡å‹ï¼šBERT/3.1-å¦‚ä½•å®ç°ä¸€ä¸ªBERT.html">
            
                <a href="../ç¯‡ç« 3-ç¼–å†™ä¸€ä¸ªTransformeræ¨¡å‹ï¼šBERT/3.1-å¦‚ä½•å®ç°ä¸€ä¸ªBERT.html">
            
                    
                    3.1-å¦‚ä½•å®ç°ä¸€ä¸ªBERT
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.2" data-path="../ç¯‡ç« 3-ç¼–å†™ä¸€ä¸ªTransformeræ¨¡å‹ï¼šBERT/3.2-å¦‚ä½•åº”ç”¨ä¸€ä¸ªBERT.html">
            
                <a href="../ç¯‡ç« 3-ç¼–å†™ä¸€ä¸ªTransformeræ¨¡å‹ï¼šBERT/3.2-å¦‚ä½•åº”ç”¨ä¸€ä¸ªBERT.html">
            
                    
                    3.2-å¦‚ä½•åº”ç”¨ä¸€ä¸ªBERT
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="3.3" data-path="../ç¯‡ç« 3-ç¼–å†™ä¸€ä¸ªTransformeræ¨¡å‹ï¼šBERT/3.3-ç¯‡ç« å°æµ‹.html">
            
                <a href="../ç¯‡ç« 3-ç¼–å†™ä¸€ä¸ªTransformeræ¨¡å‹ï¼šBERT/3.3-ç¯‡ç« å°æµ‹.html">
            
                    
                    3.3-ç¯‡ç« å°æµ‹
            
                </a>
            

            
        </li>
    

    
        
        <li class="header">ç¯‡ç« 4-ä½¿ç”¨Transformersè§£å†³NLPä»»åŠ¡</li>
        
        
    
        <li class="chapter " data-level="4.1" data-path="4.0-å‰è¨€.html">
            
                <a href="4.0-å‰è¨€.html">
            
                    
                    4.0-å‰è¨€
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.2" data-path="4.0-åŸºäºHuggingFace-Transformersçš„é¢„è®­ç»ƒæ¨¡å‹å¾®è°ƒ.html">
            
                <a href="4.0-åŸºäºHuggingFace-Transformersçš„é¢„è®­ç»ƒæ¨¡å‹å¾®è°ƒ.html">
            
                    
                    4.0-åŸºäºHuggingFace-Transformersçš„é¢„è®­ç»ƒæ¨¡å‹å¾®è°ƒ
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.3" data-path="4.1-æ–‡æœ¬åˆ†ç±».html">
            
                <a href="4.1-æ–‡æœ¬åˆ†ç±».html">
            
                    
                    4.1-æ–‡æœ¬åˆ†ç±»
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.4" data-path="4.2-åºåˆ—æ ‡æ³¨.html">
            
                <a href="4.2-åºåˆ—æ ‡æ³¨.html">
            
                    
                    4.2-åºåˆ—æ ‡æ³¨
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.5" data-path="4.3-é—®ç­”ä»»åŠ¡-æŠ½å–å¼é—®ç­”.html">
            
                <a href="4.3-é—®ç­”ä»»åŠ¡-æŠ½å–å¼é—®ç­”.html">
            
                    
                    4.3-é—®ç­”ä»»åŠ¡-æŠ½å–å¼é—®ç­”
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.6" data-path="4.4-é—®ç­”ä»»åŠ¡-å¤šé€‰é—®ç­”.html">
            
                <a href="4.4-é—®ç­”ä»»åŠ¡-å¤šé€‰é—®ç­”.html">
            
                    
                    4.4-é—®ç­”ä»»åŠ¡-å¤šé€‰é—®ç­”
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="4.7" data-path="4.5-ç”Ÿæˆä»»åŠ¡-è¯­è¨€æ¨¡å‹.html">
            
                <a href="4.5-ç”Ÿæˆä»»åŠ¡-è¯­è¨€æ¨¡å‹.html">
            
                    
                    4.5-ç”Ÿæˆä»»åŠ¡-è¯­è¨€æ¨¡å‹
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.8" data-path="4.6-ç”Ÿæˆä»»åŠ¡-æœºå™¨ç¿»è¯‘.html">
            
                <a href="4.6-ç”Ÿæˆä»»åŠ¡-æœºå™¨ç¿»è¯‘.html">
            
                    
                    4.6-ç”Ÿæˆä»»åŠ¡-æœºå™¨ç¿»è¯‘
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.9" data-path="4.7-ç”Ÿæˆä»»åŠ¡-æ‘˜è¦ç”Ÿæˆ.html">
            
                <a href="4.7-ç”Ÿæˆä»»åŠ¡-æ‘˜è¦ç”Ÿæˆ.html">
            
                    
                    4.7-ç”Ÿæˆä»»åŠ¡-æ‘˜è¦ç”Ÿæˆ
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="4.10" data-path="4.8-ç¯‡ç« å°æµ‹.html">
            
                <a href="4.8-ç¯‡ç« å°æµ‹.html">
            
                    
                    4.8-ç¯‡ç« å°æµ‹
            
                </a>
            

            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://github.com/honkit/honkit" target="blank" class="gitbook-link">
            Published with HonKit
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >4.5-ç”Ÿæˆä»»åŠ¡-è¯­è¨€æ¨¡å‹</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <p>æœ¬æ–‡æ¶‰åŠçš„jupter notebookåœ¨<a href="https://github.com/datawhalechina/learn-nlp-with-transformers/tree/main/docs/%E7%AF%87%E7%AB%A04-%E4%BD%BF%E7%94%A8Transformers%E8%A7%A3%E5%86%B3NLP%E4%BB%BB%E5%8A%A1" target="_blank">ç¯‡ç« 4ä»£ç åº“ä¸­</a>ã€‚</p>
<p>å»ºè®®ç›´æ¥ä½¿ç”¨google colab notebookæ‰“å¼€æœ¬æ•™ç¨‹ï¼Œå¯ä»¥å¿«é€Ÿä¸‹è½½ç›¸å…³æ•°æ®é›†å’Œæ¨¡å‹ã€‚
å¦‚æœæ‚¨æ­£åœ¨googleçš„colabä¸­æ‰“å¼€è¿™ä¸ªnotebookï¼Œæ‚¨å¯èƒ½éœ€è¦å®‰è£…Transformerså’ŒğŸ¤—Datasetsåº“ã€‚å°†ä»¥ä¸‹å‘½ä»¤å–æ¶ˆæ³¨é‡Šå³å¯å®‰è£…ã€‚</p>
<pre><code class="lang-python"><span class="hljs-comment"># ! pip install datasets transformers </span>
<span class="hljs-comment"># -i https://pypi.tuna.tsinghua.edu.cn/simple</span>
</code></pre>
<p>å¦‚æœæ‚¨æ˜¯åœ¨æœ¬åœ°æœºå™¨ä¸Šæ‰“å¼€è¿™ä¸ªjupyterç¬”è®°æœ¬ï¼Œè¯·ç¡®ä¿æ‚¨çš„ç¯å¢ƒå®‰è£…äº†ä¸Šè¿°åº“çš„æœ€æ–°ç‰ˆæœ¬ã€‚</p>
<p>æ‚¨å¯ä»¥åœ¨<a href="https://github.com/huggingface/transformers/tree/master/examples/language-modeling" target="_blank">è¿™é‡Œ</a>æ‰¾åˆ°è¿™ä¸ªjupyterç¬”è®°æœ¬çš„å…·ä½“çš„pythonè„šæœ¬æ–‡ä»¶ï¼Œè¿˜å¯ä»¥é€šè¿‡åˆ†å¸ƒå¼çš„æ–¹å¼ä½¿ç”¨å¤šä¸ªgpuæˆ–tpuæ¥å¾®è°ƒæ‚¨çš„æ¨¡å‹ã€‚</p>
<h1 id="å¾®è°ƒè¯­è¨€æ¨¡å‹">å¾®è°ƒè¯­è¨€æ¨¡å‹</h1>
<p>åœ¨å½“å‰jupyterç¬”è®°æœ¬ä¸­ï¼Œæˆ‘ä»¬å°†è¯´æ˜å¦‚ä½•ä½¿ç”¨è¯­è¨€æ¨¡å‹ä»»åŠ¡å¾®è°ƒä»»æ„<a href="https://github.com/huggingface/transformers" target="_blank">ğŸ¤—Transformers</a> æ¨¡å‹ã€‚ </p>
<p>æœ¬æ•™ç¨‹å°†æ¶µç›–ä¸¤ç§ç±»å‹çš„è¯­è¨€å»ºæ¨¡ä»»åŠ¡:</p>
<ul>
<li>å› æœè¯­è¨€æ¨¡å‹ï¼ˆCausal language modelingï¼ŒCLMï¼‰ï¼šæ¨¡å‹éœ€è¦é¢„æµ‹å¥å­ä¸­çš„ä¸‹ä¸€ä½ç½®å¤„çš„å­—ç¬¦ï¼ˆç±»ä¼¼BERTç±»æ¨¡å‹çš„decoderå’ŒGPTï¼Œä»å·¦å¾€å³è¾“å…¥å­—ç¬¦ï¼‰ã€‚ä¸ºäº†ç¡®ä¿æ¨¡å‹ä¸ä½œå¼Šï¼Œæ¨¡å‹ä¼šä½¿ç”¨ä¸€ä¸ªæ³¨æ„æ©ç é˜²æ­¢æ¨¡å‹çœ‹åˆ°ä¹‹åçš„å­—ç¬¦ã€‚ä¾‹å¦‚ï¼Œå½“æ¨¡å‹è¯•å›¾é¢„æµ‹å¥å­ä¸­çš„i+1ä½ç½®å¤„çš„å­—ç¬¦æ—¶ï¼Œè¿™ä¸ªæ©ç å°†é˜»æ­¢å®ƒè®¿é—®iä½ç½®ä¹‹åçš„å­—ç¬¦ã€‚</li>
</ul>
<p><img src="images/causal_language_modeling.png" alt="æ¨ç†è¡¨ç¤ºå› æœè¯­è¨€å»ºæ¨¡ä»»åŠ¡å›¾ç‰‡"></img></p>
<ul>
<li>æ©è”½è¯­è¨€å»ºæ¨¡ï¼ˆMasked language modelingï¼ŒMLMï¼‰ï¼šæ¨¡å‹éœ€è¦æ¢å¤è¾“å…¥ä¸­è¢«"MASK"æ‰çš„ä¸€äº›å­—ç¬¦ï¼ˆBERTç±»æ¨¡å‹çš„é¢„è®­ç»ƒä»»åŠ¡ï¼‰ã€‚è¿™ç§æ–¹å¼æ¨¡å‹å¯ä»¥çœ‹åˆ°æ•´ä¸ªå¥å­ï¼Œå› æ­¤æ¨¡å‹å¯ä»¥æ ¹æ®â€œ[MASK]â€æ ‡è®°ä¹‹å‰å’Œä¹‹åçš„å­—ç¬¦æ¥é¢„æµ‹è¯¥ä½ç½®è¢«â€œ[MASK]â€ä¹‹å‰çš„å­—ç¬¦ã€‚</li>
</ul>
<p><img src="images/masked_language_modeling.png" alt="Widget inference representing the masked language modeling task"></img></p>
<p>æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†è¯´æ˜å¦‚ä½•è½»æ¾åœ°ä¸ºæ¯ä¸ªä»»åŠ¡åŠ è½½å’Œé¢„å¤„ç†æ•°æ®é›†ï¼Œä»¥åŠå¦‚ä½•ä½¿ç”¨â€œTrainerâ€APIå¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒã€‚</p>
<p>å½“ç„¶æ‚¨ä¹Ÿå¯ä»¥ç›´æ¥åœ¨åˆ†å¸ƒå¼ç¯å¢ƒæˆ–TPUä¸Šè¿è¡Œè¯¥jupyterç¬”è®°æœ¬çš„pythonè„šæœ¬ç‰ˆæœ¬ï¼Œå¯ä»¥åœ¨<a href="https://github.com/huggingface/transformers/tree/master/examples" target="_blank">examplesæ–‡ä»¶å¤¹</a>ä¸­æ‰¾åˆ°ã€‚</p>
<h2 id="å‡†å¤‡æ•°æ®">å‡†å¤‡æ•°æ®</h2>
<p>åœ¨æ¥ä¸‹æ¥çš„è¿™äº›ä»»åŠ¡ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨<a href="https://huggingface.co/datasets/wikitext#data-instances" target="_blank">Wikitext 2</a>æ•°æ®é›†ä½œä¸ºç¤ºä¾‹ã€‚æ‚¨å¯ä»¥é€šè¿‡ğŸ¤—Datasetsåº“åŠ è½½è¯¥æ•°æ®é›†ï¼š</p>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> load_dataset
datasets = load_dataset(<span class="hljs-string">'wikitext'</span>, <span class="hljs-string">'wikitext-2-raw-v1'</span>)
</code></pre>
<pre><code>Reusing dataset wikitext (/Users/niepig/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/aa5e094000ec7afeb74c3be92c88313cd6f132d564c7effd961c10fd47c76f20)
</code></pre><p>å¦‚æœç¢°åˆ°ä»¥ä¸‹é”™è¯¯ï¼š
<img src="images/request_error.png" alt="request Error"></img></p>
<p>è§£å†³æ–¹æ¡ˆ:</p>
<p>MACç”¨æˆ·: åœ¨ <code>/etc/hosts</code> æ–‡ä»¶ä¸­æ·»åŠ ä¸€è¡Œ <code>199.232.68.133  raw.githubusercontent.com</code></p>
<p>Windowsoç”¨æˆ·: åœ¨ <code>C:\Windows\System32\drivers\etc\hosts</code>  æ–‡ä»¶ä¸­æ·»åŠ ä¸€è¡Œ <code>199.232.68.133  raw.githubusercontent.com</code></p>
<p>å½“ç„¶æ‚¨ä¹Ÿå¯ä»¥ç”¨å…¬å¼€åœ¨<a href="https://huggingface.co/datasets" target="_blank">hub</a>ä¸Šçš„ä»»ä½•æ•°æ®é›†æ›¿æ¢ä¸Šé¢çš„æ•°æ®é›†ï¼Œæˆ–è€…ä½¿ç”¨æ‚¨è‡ªå·±çš„æ–‡ä»¶ã€‚åªéœ€å–æ¶ˆæ³¨é‡Šä»¥ä¸‹å•å…ƒæ ¼ï¼Œå¹¶å°†è·¯å¾„æ›¿æ¢ä¸ºå°†å¯¼è‡´æ‚¨çš„æ–‡ä»¶è·¯å¾„ï¼š</p>
<pre><code class="lang-python"><span class="hljs-comment"># datasets = load_dataset("text", data_files={"train": path_to_train.txt, "validation": path_to_validation.txt}</span>
</code></pre>
<p>æ‚¨è¿˜å¯ä»¥ä»csvæˆ–JSONæ–‡ä»¶åŠ è½½æ•°æ®é›†ï¼Œæ›´å¤šä¿¡æ¯è¯·å‚é˜…<a href="https://huggingface.co/docs/datasets/loading_datasets.html#from-local-files" target="_blank">å®Œæ•´æ–‡æ¡£</a>ã€‚</p>
<p>è¦è®¿é—®ä¸€ä¸ªæ•°æ®ä¸­å®é™…çš„å…ƒç´ ï¼Œæ‚¨éœ€è¦å…ˆé€‰æ‹©ä¸€ä¸ªkeyï¼Œç„¶åç»™å‡ºä¸€ä¸ªç´¢å¼•:</p>
<pre><code class="lang-python">datasets[<span class="hljs-string">"train"</span>][<span class="hljs-number">10</span>]
</code></pre>
<pre><code>{'text': ' The game \'s battle system , the BliTZ system , is carried over directly from Valkyira Chronicles . During missions , players select each unit using a top @-@ down perspective of the battlefield map : once a character is selected , the player moves the character around the battlefield in third @-@ person . A character can only act once per @-@ turn , but characters can be granted multiple turns at the expense of other characters \' turns . Each character has a field and distance of movement limited by their Action Gauge . Up to nine characters can be assigned to a single mission . During gameplay , characters will call out if something happens to them , such as their health points ( HP ) getting low or being knocked out by enemy attacks . Each character has specific " Potentials " , skills unique to each character . They are divided into " Personal Potential " , which are innate skills that remain unaltered unless otherwise dictated by the story and can either help or impede a character , and " Battle Potentials " , which are grown throughout the game and always grant boons to a character . To learn Battle Potentials , each character has a unique " Masters Table " , a grid @-@ based skill table that can be used to acquire and link different skills . Characters also have Special Abilities that grant them temporary boosts on the battlefield : Kurt can activate " Direct Command " and move around the battlefield without depleting his Action Point gauge , the character Reila can shift into her " Valkyria Form " and become invincible , while Imca can target multiple enemy units with her heavy weapon . \n'}
</code></pre><p>ä¸ºäº†å¿«é€Ÿäº†è§£æ•°æ®çš„ç»“æ„ï¼Œä¸‹é¢çš„å‡½æ•°å°†æ˜¾ç¤ºæ•°æ®é›†ä¸­éšæœºé€‰å–çš„ä¸€äº›ç¤ºä¾‹ã€‚</p>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> datasets <span class="hljs-keyword">import</span> ClassLabel
<span class="hljs-keyword">import</span> random
<span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">from</span> IPython.display <span class="hljs-keyword">import</span> display, HTML

<span class="hljs-keyword">def</span> <span class="hljs-title function_">show_random_elements</span>(<span class="hljs-params">dataset, num_examples=<span class="hljs-number">10</span></span>):
    <span class="hljs-keyword">assert</span> num_examples &lt;= <span class="hljs-built_in">len</span>(dataset), <span class="hljs-string">"Can't pick more elements than there are in the dataset."</span>
    picks = []
    <span class="hljs-keyword">for</span> _ <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(num_examples):
        pick = random.randint(<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(dataset)-<span class="hljs-number">1</span>)
        <span class="hljs-keyword">while</span> pick <span class="hljs-keyword">in</span> picks:
            pick = random.randint(<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(dataset)-<span class="hljs-number">1</span>)
        picks.append(pick)

    df = pd.DataFrame(dataset[picks])
    <span class="hljs-keyword">for</span> column, typ <span class="hljs-keyword">in</span> dataset.features.items():
        <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(typ, ClassLabel):
            df[column] = df[column].transform(<span class="hljs-keyword">lambda</span> i: typ.names[i])
    display(HTML(df.to_html()))
</code></pre>
<pre><code class="lang-python">show_random_elements(datasets[<span class="hljs-string">"train"</span>])
</code></pre>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>On 3 March 1967 , parliament decided to build four short take @-@ off and landing airports along the Helgeland coast between Trondheim and BodÃ¸ . Braathens placed an order for a de Havilland Canada DHC @-@ 6 Twin Otter and planned to start the company Braathens STOL . It applied to operate the route without subsidies , but the concession was rejected and granted with subsidies to WiderÃ¸e , which had been operating the routes using seaplanes . \n</td>
    </tr>
    <tr>
      <th>1</th>
      <td></td>
    </tr>
    <tr>
      <th>2</th>
      <td>Rao Ramesh was cast as a tantrik who helps Gill 's character in the present era . Mumaith Khan was selected for another item number , a remix version of the hit song " Bangaru Kodipetta " from Gharana Mogudu ( 1992 ) ; Gharana Mogudu 's music was also composed by M. M. Keeravani . Chiranjeevi made a special appearance after the song , making Magadheera the first film he appeared in after his entry into politics . When Rajamouli suggested the idea of a cameo appearance , Chiranjeevi was initially hesitant till the director narrated the complete sequence and the importance of the song . \n</td>
    </tr>
    <tr>
      <th>3</th>
      <td></td>
    </tr>
    <tr>
      <th>4</th>
      <td></td>
    </tr>
    <tr>
      <th>5</th>
      <td>= = = Total Nonstop Action Wrestling ( 2015 â€“ present ) = = = \n</td>
    </tr>
    <tr>
      <th>6</th>
      <td>The Daily Telegraph gave the visual novel the award for " Best Script " in its video game awards of 2011 , stating that " Love 's layered narrative of a high school teacher embroiled in his student â€™ s worries goes places most mainstream video games wouldn 't dare . " \n</td>
    </tr>
    <tr>
      <th>7</th>
      <td></td>
    </tr>
    <tr>
      <th>8</th>
      <td></td>
    </tr>
    <tr>
      <th>9</th>
      <td></td>
    </tr>
  </tbody>
</table>


<p>æ­£å¦‚æˆ‘ä»¬æ‰€çœ‹åˆ°çš„ï¼Œä¸€äº›æ–‡æœ¬æ˜¯ç»´åŸºç™¾ç§‘æ–‡ç« çš„å®Œæ•´æ®µè½ï¼Œè€Œå…¶ä»–çš„åªæ˜¯æ ‡é¢˜æˆ–ç©ºè¡Œã€‚</p>
<h2 id="å› æœè¯­è¨€æ¨¡å‹ï¼ˆcausal-language-modelingï¼Œclmï¼‰">å› æœè¯­è¨€æ¨¡å‹ï¼ˆCausal Language Modelingï¼ŒCLMï¼‰</h2>
<p>å¯¹äºå› æœè¯­è¨€æ¨¡å‹(CLM)ï¼Œæˆ‘ä»¬é¦–å…ˆè·å–åˆ°æ•°æ®é›†ä¸­çš„æ‰€æœ‰æ–‡æœ¬ï¼Œå¹¶åœ¨å®ƒä»¬è¢«åˆ†è¯åå°†å®ƒä»¬è¿æ¥èµ·æ¥ã€‚ç„¶åï¼Œæˆ‘ä»¬å°†åœ¨ç‰¹å®šåºåˆ—é•¿åº¦çš„ä¾‹å­ä¸­æ‹†åˆ†å®ƒä»¬ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ¨¡å‹å°†æ¥æ”¶å¦‚ä¸‹çš„è¿ç»­æ–‡æœ¬å—:</p>
<pre><code>æ–‡æœ¬1
</code></pre><p>æˆ–</p>
<pre><code>æ–‡æœ¬1ç»“å°¾ [BOS_TOKEN] æ–‡æœ¬2å¼€å¤´
</code></pre><p>å–å†³äºå®ƒä»¬æ˜¯å¦è·¨è¶Šæ•°æ®é›†ä¸­çš„å‡ ä¸ªåŸå§‹æ–‡æœ¬ã€‚æ ‡ç­¾å°†ä¸è¾“å…¥ç›¸åŒï¼Œä½†å‘å·¦ç§»åŠ¨ã€‚</p>
<p>åœ¨æœ¬ä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨<a href="https://huggingface.co/distilgpt2" target="_blank"><code>distilgpt2</code></a> æ¨¡å‹ã€‚æ‚¨åŒæ ·ä¹Ÿå¯ä»¥é€‰æ‹©<a href="https://huggingface.co/models?filter=causal-lm" target="_blank">è¿™é‡Œ</a>åˆ—å‡ºçš„ä»»ä½•ä¸€ä¸ªcheckpoint:</p>
<pre><code class="lang-python">model_checkpoint = <span class="hljs-string">"distilgpt2"</span>
</code></pre>
<p>ä¸ºäº†ç”¨è®­ç»ƒæ¨¡å‹æ—¶ä½¿ç”¨çš„è¯æ±‡å¯¹æ‰€æœ‰æ–‡æœ¬è¿›è¡Œæ ‡è®°ï¼Œæˆ‘ä»¬å¿…é¡»ä¸‹è½½ä¸€ä¸ªé¢„å…ˆè®­ç»ƒè¿‡çš„åˆ†è¯å™¨ï¼ˆTokenizerï¼‰ã€‚è€Œè¿™äº›æ“ä½œéƒ½å¯ä»¥ç”±AutoTokenizerç±»å®Œæˆ:</p>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=<span class="hljs-literal">True</span>)
</code></pre>
<p>æˆ‘ä»¬ç°åœ¨å¯ä»¥å¯¹æ‰€æœ‰çš„æ–‡æœ¬è°ƒç”¨åˆ†è¯å™¨ï¼Œè¯¥æ“ä½œå¯ä»¥ç®€å•åœ°ä½¿ç”¨æ¥è‡ªDatasetsåº“çš„mapæ–¹æ³•å®ç°ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å®šä¹‰ä¸€ä¸ªåœ¨æ–‡æœ¬ä¸Šè°ƒç”¨æ ‡è®°å™¨çš„å‡½æ•°:</p>
<pre><code class="lang-python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">tokenize_function</span>(<span class="hljs-params">examples</span>):
    <span class="hljs-keyword">return</span> tokenizer(examples[<span class="hljs-string">"text"</span>])
</code></pre>
<p>ç„¶åæˆ‘ä»¬å°†å®ƒåº”ç”¨åˆ°datasetså¯¹è±¡ä¸­çš„åˆ†è¯ï¼Œä½¿ç”¨<code>batch=True</code>å’Œ<code>4</code>ä¸ªè¿›ç¨‹æ¥åŠ é€Ÿé¢„å¤„ç†ã€‚è€Œä¹‹åæˆ‘ä»¬å¹¶ä¸éœ€è¦<code>text</code>åˆ—ï¼Œæ‰€ä»¥å°†å…¶èˆå¼ƒã€‚</p>
<pre><code class="lang-python">tokenized_datasets = datasets.<span class="hljs-built_in">map</span>(tokenize_function, batched=<span class="hljs-literal">True</span>, num_proc=<span class="hljs-number">4</span>, remove_columns=[<span class="hljs-string">"text"</span>])
</code></pre>
<p>å¦‚æœæˆ‘ä»¬ç°åœ¨æŸ¥çœ‹æ•°æ®é›†çš„ä¸€ä¸ªå…ƒç´ ï¼Œæˆ‘ä»¬ä¼šçœ‹åˆ°æ–‡æœ¬å·²ç»è¢«æ¨¡å‹æ‰€éœ€çš„input_idsæ‰€å–ä»£:</p>
<pre><code class="lang-python">tokenized_datasets[<span class="hljs-string">"train"</span>][<span class="hljs-number">1</span>]
</code></pre>
<pre><code>{'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1],
 'input_ids': [796, 569, 18354, 7496, 17740, 6711, 796, 220, 198]}
</code></pre><p>ä¸‹ä¸€æ­¥å°±æœ‰ç‚¹å°å›°éš¾äº†ï¼šæˆ‘ä»¬éœ€è¦å°†æ‰€æœ‰æ–‡æœ¬è¿æ¥åœ¨ä¸€èµ·ï¼Œç„¶åå°†ç»“æœåˆ†å‰²æˆç‰¹å®š<code>block_size</code>çš„å°å—ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å°†å†æ¬¡ä½¿ç”¨<code>map</code>æ–¹æ³•ï¼Œå¹¶ä½¿ç”¨é€‰é¡¹<code>batch=True</code>ã€‚è¿™ä¸ªé€‰é¡¹å…è®¸æˆ‘ä»¬é€šè¿‡è¿”å›ä¸åŒæ•°é‡çš„æ ·æœ¬æ¥æ”¹å˜æ•°æ®é›†ä¸­çš„æ ·æœ¬æ•°é‡ã€‚é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæˆ‘ä»¬å¯ä»¥ä»ä¸€æ‰¹ç¤ºä¾‹ä¸­åˆ›å»ºæ–°çš„ç¤ºä¾‹ã€‚</p>
<p>é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦è·å–é¢„è®­ç»ƒæ¨¡å‹æ—¶æ‰€ä½¿ç”¨çš„æœ€å¤§é•¿åº¦ã€‚æœ€å¤§é•¿åº¦åœ¨è¿™é‡Œè®¾ç½®ä¸º128ï¼Œä»¥é˜²æ‚¨çš„æ˜¾å­˜çˆ†ç‚¸ğŸ’¥ã€‚</p>
<pre><code class="lang-python"><span class="hljs-comment"># block_size = tokenizer.model_max_length</span>
block_size = <span class="hljs-number">128</span>
</code></pre>
<p>ç„¶åæˆ‘ä»¬ç¼–å†™é¢„å¤„ç†å‡½æ•°æ¥å¯¹æˆ‘ä»¬çš„æ–‡æœ¬è¿›è¡Œåˆ†ç»„:</p>
<pre><code class="lang-python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">group_texts</span>(<span class="hljs-params">examples</span>):
    <span class="hljs-comment"># æ‹¼æ¥æ‰€æœ‰æ–‡æœ¬</span>
    concatenated_examples = {k: <span class="hljs-built_in">sum</span>(examples[k], []) <span class="hljs-keyword">for</span> k <span class="hljs-keyword">in</span> examples.keys()}
    total_length = <span class="hljs-built_in">len</span>(concatenated_examples[<span class="hljs-built_in">list</span>(examples.keys())[<span class="hljs-number">0</span>]])
    <span class="hljs-comment"># æˆ‘ä»¬å°†ä½™æ•°å¯¹åº”çš„éƒ¨åˆ†å»æ‰ã€‚ä½†å¦‚æœæ¨¡å‹æ”¯æŒçš„è¯ï¼Œå¯ä»¥æ·»åŠ paddingï¼Œæ‚¨å¯ä»¥æ ¹æ®éœ€è¦å®šåˆ¶æ­¤éƒ¨ä»¶ã€‚</span>
    total_length = (total_length // block_size) * block_size
    <span class="hljs-comment"># é€šè¿‡max_lenè¿›è¡Œåˆ†å‰²ã€‚</span>
    result = {
        k: [t[i : i + block_size] <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, total_length, block_size)]
        <span class="hljs-keyword">for</span> k, t <span class="hljs-keyword">in</span> concatenated_examples.items()
    }
    result[<span class="hljs-string">"labels"</span>] = result[<span class="hljs-string">"input_ids"</span>].copy()
    <span class="hljs-keyword">return</span> result
</code></pre>
<p>é¦–å…ˆæ³¨æ„ï¼Œæˆ‘ä»¬å¤åˆ¶äº†æ ‡ç­¾çš„è¾“å…¥ã€‚</p>
<p>è¿™æ˜¯å› ä¸ºğŸ¤—transformeråº“çš„æ¨¡å‹é»˜è®¤å‘å³ç§»åŠ¨ï¼Œæ‰€ä»¥æˆ‘ä»¬ä¸éœ€è¦æ‰‹åŠ¨æ“ä½œã€‚</p>
<p>è¿˜è¦æ³¨æ„ï¼Œåœ¨é»˜è®¤æƒ…å†µä¸‹ï¼Œ<code>map</code>æ–¹æ³•å°†å‘é€ä¸€æ‰¹1,000ä¸ªç¤ºä¾‹ï¼Œç”±é¢„å¤„ç†å‡½æ•°å¤„ç†ã€‚å› æ­¤ï¼Œåœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å°†åˆ é™¤å‰©ä½™éƒ¨åˆ†ï¼Œä½¿è¿æ¥çš„æ ‡è®°åŒ–æ–‡æœ¬æ¯1000ä¸ªç¤ºä¾‹ä¸º<code>block_size</code>çš„å€æ•°ã€‚æ‚¨å¯ä»¥é€šè¿‡ä¼ é€’æ›´é«˜çš„æ‰¹å¤„ç†å¤§å°æ¥è°ƒæ•´æ­¤è¡Œä¸º(å½“ç„¶è¿™ä¹Ÿä¼šè¢«å¤„ç†å¾—æ›´æ…¢)ã€‚ä½ ä¹Ÿå¯ä»¥ä½¿ç”¨<code>multiprocessing</code>æ¥åŠ é€Ÿé¢„å¤„ç†:</p>
<pre><code class="lang-python">lm_datasets = tokenized_datasets.<span class="hljs-built_in">map</span>(
    group_texts,
    batched=<span class="hljs-literal">True</span>,
    batch_size=<span class="hljs-number">1000</span>,
    num_proc=<span class="hljs-number">4</span>,
)
</code></pre>
<p>ç°åœ¨æˆ‘ä»¬å¯ä»¥æ£€æŸ¥æ•°æ®é›†æ˜¯å¦å‘ç”Ÿäº†å˜åŒ–ï¼šç°åœ¨æ ·æœ¬åŒ…å«äº†<code>block_size</code>è¿ç»­å­—ç¬¦å—ï¼Œå¯èƒ½è·¨è¶Šäº†å‡ ä¸ªåŸå§‹æ–‡æœ¬ã€‚</p>
<pre><code class="lang-python">tokenizer.decode(lm_datasets[<span class="hljs-string">"train"</span>][<span class="hljs-number">1</span>][<span class="hljs-string">"input_ids"</span>])
</code></pre>
<pre><code>' game and follows the " Nameless ", a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit " Calamaty Raven ". \n The game began development in 2010, carrying over a large portion of the work done on Valkyria Chronicles II. While it retained the standard features of the series, it also underwent multiple adjustments, such as making the game more forgiving for series newcomers. Character designer Raita Honjou and composer Hitoshi Sakimoto both returned from previous entries, along with Valkyria Chronicles II director Takeshi Oz'
</code></pre><p>æ—¢ç„¶æ•°æ®å·²ç»æ¸…ç†å®Œæ¯•ï¼Œæˆ‘ä»¬å°±å¯ä»¥å®ä¾‹åŒ–æˆ‘ä»¬çš„è®­ç»ƒå™¨äº†ã€‚æˆ‘ä»¬å°†å»ºç«‹ä¸€ä¸ªæ¨¡å‹:</p>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForCausalLM
model = AutoModelForCausalLM.from_pretrained(model_checkpoint)
</code></pre>
<p>æ£€æŸ¥torchç‰ˆæœ¬</p>
<pre><code class="lang-python">
<span class="hljs-keyword">import</span> importlib.util
<span class="hljs-comment"># import importlib_metadata</span>
a = importlib.util.find_spec(<span class="hljs-string">"torch"</span>) <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>
<span class="hljs-built_in">print</span>(a)
<span class="hljs-comment"># _torch_version = importlib_metadata.version("torch")</span>
<span class="hljs-comment"># print(_torch_version)</span>
</code></pre>
<pre><code>True
</code></pre><p>å’Œä¸€äº›<code>TrainingArguments</code>:</p>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> Trainer, TrainingArguments
</code></pre>
<pre><code class="lang-python">training_args = TrainingArguments(
    <span class="hljs-string">"test-clm"</span>,
    evaluation_strategy = <span class="hljs-string">"epoch"</span>,
    learning_rate=<span class="hljs-number">2e-5</span>,
    weight_decay=<span class="hljs-number">0.01</span>,
)
</code></pre>
<p>æˆ‘ä»¬æŠŠè¿™äº›éƒ½ä¼ é€’ç»™<code>Trainer</code>ç±»:</p>
<pre><code class="lang-python">trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=lm_datasets[<span class="hljs-string">"train"</span>],
    eval_dataset=lm_datasets[<span class="hljs-string">"validation"</span>],
)
</code></pre>
<p>ç„¶åå°±å¯ä»¥è®­ç»ƒæˆ‘ä»¬çš„æ¨¡å‹ğŸŒ¶:</p>
<pre><code class="lang-python">trainer.train()
</code></pre>
<pre><code>  0%|          | 31/7002 [04:16&lt;14:27:52,  7.47s/it]
</code></pre><p>ä¸€æ—¦è®­ç»ƒå®Œæˆï¼Œæˆ‘ä»¬å°±å¯ä»¥è¯„ä¼°æˆ‘ä»¬çš„æ¨¡å‹ï¼Œå¾—åˆ°å®ƒåœ¨éªŒè¯é›†ä¸Šçš„perplexityï¼Œå¦‚ä¸‹æ‰€ç¤º:</p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> math
eval_results = trainer.evaluate()
<span class="hljs-built_in">print</span>(<span class="hljs-string">f"Perplexity: <span class="hljs-subst">{math.exp(eval_results[<span class="hljs-string">'eval_loss'</span>]):<span class="hljs-number">.2</span>f}</span>"</span>)
</code></pre>
<h2 id="æ©è”½è¯­è¨€æ¨¡å‹ï¼ˆmask-language-modelingï¼Œmlmï¼‰">æ©è”½è¯­è¨€æ¨¡å‹ï¼ˆMask Language Modelingï¼ŒMLMï¼‰</h2>
<p>æ©è”½è¯­è¨€æ¨¡å‹(MLM)æˆ‘ä»¬å°†ä½¿ç”¨ç›¸åŒçš„æ•°æ®é›†é¢„å¤„ç†å’Œä»¥å‰ä¸€æ ·ç”¨ä¸€ä¸ªé¢å¤–çš„æ­¥éª¤ï¼š</p>
<p>æˆ‘ä»¬å°†éšæœº"MASK"ä¸€äº›å­—ç¬¦(ä½¿ç”¨"[MASK]"è¿›è¡Œæ›¿æ¢)ä»¥åŠè°ƒæ•´æ ‡ç­¾ä¸ºåªåŒ…å«åœ¨"[MASK]"ä½ç½®å¤„çš„æ ‡ç­¾(å› ä¸ºæˆ‘ä»¬ä¸éœ€è¦é¢„æµ‹æ²¡æœ‰è¢«"MASK"çš„å­—ç¬¦)ã€‚</p>
<p>åœ¨æœ¬ä¾‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨<a href="https://huggingface.co/distilroberta-base" target="_blank"><code>distilroberta-base</code></a>æ¨¡å‹ã€‚æ‚¨åŒæ ·ä¹Ÿå¯ä»¥é€‰æ‹©<a href="https://huggingface.co/models?filter=causal-lm" target="_blank">è¿™é‡Œ</a>åˆ—å‡ºçš„ä»»ä½•ä¸€ä¸ªcheckpoint:</p>
<pre><code class="lang-python">model_checkpoint = <span class="hljs-string">"distilroberta-base"</span>
</code></pre>
<p>æˆ‘ä»¬å¯ä»¥åƒä¹‹å‰ä¸€æ ·åº”ç”¨ç›¸åŒçš„åˆ†è¯å™¨å‡½æ•°ï¼Œæˆ‘ä»¬åªéœ€è¦æ›´æ–°æˆ‘ä»¬çš„åˆ†è¯å™¨æ¥ä½¿ç”¨åˆšåˆšé€‰æ‹©çš„checkpoint:</p>
<pre><code class="lang-python">tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=<span class="hljs-literal">True</span>)
tokenized_datasets = datasets.<span class="hljs-built_in">map</span>(tokenize_function, batched=<span class="hljs-literal">True</span>, num_proc=<span class="hljs-number">4</span>, remove_columns=[<span class="hljs-string">"text"</span>])
</code></pre>
<p>åƒä¹‹å‰ä¸€æ ·ï¼Œæˆ‘ä»¬æŠŠæ–‡æœ¬åˆ†ç»„åœ¨ä¸€èµ·ï¼Œå¹¶æŠŠå®ƒä»¬åˆ†æˆé•¿åº¦ä¸º<code>block_size</code>çš„æ ·æœ¬ã€‚å¦‚æœæ‚¨çš„æ•°æ®é›†ç”±å•ç‹¬çš„å¥å­ç»„æˆï¼Œåˆ™å¯ä»¥è·³è¿‡è¿™ä¸€æ­¥ã€‚</p>
<pre><code class="lang-python">lm_datasets = tokenized_datasets.<span class="hljs-built_in">map</span>(
    group_texts,
    batched=<span class="hljs-literal">True</span>,
    batch_size=<span class="hljs-number">1000</span>,
    num_proc=<span class="hljs-number">4</span>,
)
</code></pre>
<p>å‰©ä¸‹çš„å’Œæˆ‘ä»¬ä¹‹å‰çš„åšæ³•éå¸¸ç›¸ä¼¼ï¼Œåªæœ‰ä¸¤ä¸ªä¾‹å¤–ã€‚é¦–å…ˆæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªé€‚åˆæ©è”½è¯­è¨€æ¨¡å‹çš„æ¨¡å‹:</p>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> AutoModelForMaskedLM
model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)
</code></pre>
<p>å…¶æ¬¡ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªç‰¹æ®Šçš„data_collatorã€‚data_collatoræ˜¯ä¸€ä¸ªå‡½æ•°ï¼Œè´Ÿè´£è·å–æ ·æœ¬å¹¶å°†å®ƒä»¬æ‰¹å¤„ç†æˆå¼ é‡ã€‚</p>
<p>åœ¨å‰é¢çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬æ²¡æœ‰ä»€ä¹ˆç‰¹æ®Šçš„äº‹æƒ…è¦åšï¼Œæ‰€ä»¥æˆ‘ä»¬åªä½¿ç”¨è¿™ä¸ªå‚æ•°çš„é»˜è®¤å€¼ã€‚è¿™é‡Œæˆ‘ä»¬è¦åšéšæœº"MASK"ã€‚</p>
<p>æˆ‘ä»¬å¯ä»¥å°†å…¶ä½œä¸ºé¢„å¤„ç†æ­¥éª¤(<code>tokenizer</code>)è¿›è¡Œå¤„ç†ï¼Œä½†åœ¨æ¯ä¸ªé˜¶æ®µï¼Œå­—ç¬¦æ€»æ˜¯ä»¥ç›¸åŒçš„æ–¹å¼è¢«æ©ç›–ã€‚é€šè¿‡åœ¨data_collatorä¸­æ‰§è¡Œè¿™ä¸€æ­¥ï¼Œæˆ‘ä»¬å¯ä»¥ç¡®ä¿æ¯æ¬¡æ£€æŸ¥æ•°æ®æ—¶éƒ½ä»¥æ–°çš„æ–¹å¼å®Œæˆéšæœºæ©è”½ã€‚</p>
<p>ä¸ºäº†å®ç°æ©è”½ï¼Œ<code>Transformers</code>ä¸ºæ©è”½è¯­è¨€æ¨¡å‹æä¾›äº†ä¸€ä¸ª<code>DataCollatorForLanguageModeling</code>ã€‚æˆ‘ä»¬å¯ä»¥è°ƒæ•´æ©è”½çš„æ¦‚ç‡:</p>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> DataCollatorForLanguageModeling
data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=<span class="hljs-number">0.15</span>)
</code></pre>
<p>ç„¶åæˆ‘ä»¬è¦æŠŠæ‰€æœ‰çš„ä¸œè¥¿äº¤ç»™trainerï¼Œç„¶åå¼€å§‹è®­ç»ƒ:</p>
<pre><code class="lang-python">trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=lm_datasets[<span class="hljs-string">"train"</span>],
    eval_dataset=lm_datasets[<span class="hljs-string">"validation"</span>],
    data_collator=data_collator,
)
</code></pre>
<pre><code class="lang-python">trainer.train()
</code></pre>
<p>åƒä»¥å‰ä¸€æ ·ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°æˆ‘ä»¬çš„æ¨¡å‹ã€‚</p>
<p>ä¸CLMç›®æ ‡ç›¸æ¯”ï¼Œå›°æƒ‘åº¦è¦ä½å¾—å¤šï¼Œå› ä¸ºå¯¹äºMLMç›®æ ‡ï¼Œæˆ‘ä»¬åªéœ€è¦å¯¹éšè—çš„ä»¤ç‰Œ(åœ¨è¿™é‡Œå æ€»æ•°çš„15%)è¿›è¡Œé¢„æµ‹ï¼ŒåŒæ—¶å¯ä»¥è®¿é—®å…¶ä½™çš„ä»¤ç‰Œã€‚</p>
<p>å› æ­¤ï¼Œå¯¹äºæ¨¡å‹æ¥è¯´ï¼Œè¿™æ˜¯ä¸€é¡¹æ›´å®¹æ˜“çš„ä»»åŠ¡ã€‚</p>
<pre><code class="lang-python">eval_results = trainer.evaluate()
<span class="hljs-built_in">print</span>(<span class="hljs-string">f"Perplexity: <span class="hljs-subst">{math.exp(eval_results[<span class="hljs-string">'eval_loss'</span>]):<span class="hljs-number">.2</span>f}</span>"</span>)
</code></pre>
<pre><code class="lang-python">ä¸è¦å¿˜è®°å°†ä½ çš„æ¨¡å‹[ä¸Šä¼ ](https://huggingface.co/transformers/model_sharing.html)åˆ°[ğŸ¤— æ¨¡å‹ä¸­å¿ƒ](https://huggingface.co/models)ã€‚
</code></pre>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="4.4-é—®ç­”ä»»åŠ¡-å¤šé€‰é—®ç­”.html" class="navigation navigation-prev " aria-label="Previous page: 4.4-é—®ç­”ä»»åŠ¡-å¤šé€‰é—®ç­”">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="4.6-ç”Ÿæˆä»»åŠ¡-æœºå™¨ç¿»è¯‘.html" class="navigation navigation-next " aria-label="Next page: 4.6-ç”Ÿæˆä»»åŠ¡-æœºå™¨ç¿»è¯‘">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"4.5-ç”Ÿæˆä»»åŠ¡-è¯­è¨€æ¨¡å‹","level":"4.7","depth":1,"next":{"title":"4.6-ç”Ÿæˆä»»åŠ¡-æœºå™¨ç¿»è¯‘","level":"4.8","depth":1,"path":"ç¯‡ç« 4-ä½¿ç”¨Transformersè§£å†³NLPä»»åŠ¡/4.6-ç”Ÿæˆä»»åŠ¡-æœºå™¨ç¿»è¯‘.md","ref":"./ç¯‡ç« 4-ä½¿ç”¨Transformersè§£å†³NLPä»»åŠ¡/4.6-ç”Ÿæˆä»»åŠ¡-æœºå™¨ç¿»è¯‘.md","articles":[]},"previous":{"title":"4.4-é—®ç­”ä»»åŠ¡-å¤šé€‰é—®ç­”","level":"4.6","depth":1,"path":"ç¯‡ç« 4-ä½¿ç”¨Transformersè§£å†³NLPä»»åŠ¡/4.4-é—®ç­”ä»»åŠ¡-å¤šé€‰é—®ç­”.md","ref":"./ç¯‡ç« 4-ä½¿ç”¨Transformersè§£å†³NLPä»»åŠ¡/4.4-é—®ç­”ä»»åŠ¡-å¤šé€‰é—®ç­”.md","articles":[]},"dir":"ltr"},"config":{"gitbook":"*","theme":"default","variables":{},"plugins":["livereload"],"pluginsConfig":{"livereload":{},"highlight":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56},"embedFonts":false},"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"}},"file":{"path":"ç¯‡ç« 4-ä½¿ç”¨Transformersè§£å†³NLPä»»åŠ¡/4.5-ç”Ÿæˆä»»åŠ¡-è¯­è¨€æ¨¡å‹.md","mtime":"2024-08-23T15:34:37.400Z","type":"markdown"},"gitbook":{"version":"5.1.4","time":"2024-08-23T15:50:04.957Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <noscript>
        <style>
            .honkit-cloak {
                display: block !important;
            }
        </style>
    </noscript>
    <script>
        // Restore sidebar state as critical path for prevent layout shift
        function __init__getSidebarState(defaultValue){
            var baseKey = "";
            var key = baseKey + ":sidebar";
            try {
                var value = localStorage[key];
                if (value === undefined) {
                    return defaultValue;
                }
                var parsed = JSON.parse(value);
                return parsed == null ? defaultValue : parsed;
            } catch (e) {
                return defaultValue;
            }
        }
        function __init__restoreLastSidebarState() {
            var isMobile = window.matchMedia("(max-width: 600px)").matches;
            if (isMobile) {
                // Init last state if not mobile
                return;
            }
            var sidebarState = __init__getSidebarState(true);
            var book = document.querySelector(".book");
            // Show sidebar if it enabled
            if (sidebarState && book) {
                book.classList.add("without-animation", "with-summary");
            }
        }

        try {
            __init__restoreLastSidebarState();
        } finally {
            var book = document.querySelector(".book");
            book.classList.remove("honkit-cloak");
        }
    </script>
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="../gitbook/gitbook-plugin-livereload/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

